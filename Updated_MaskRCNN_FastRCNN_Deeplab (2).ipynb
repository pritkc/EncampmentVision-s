{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQgJ56FfBJDS",
        "outputId": "98df8675-7f62-4ce3-88c5-c08abb35f0f3"
      },
      "outputs": [],
      "source": [
        "!pip install albumentations\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "498gd21FFr_Z",
        "outputId": "576b95ea-f8d6-4cad-996d-2071c3324d01"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "794kNuvD79KD",
        "outputId": "9a743950-6a38-4667-d117-0722e68bdc08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "torchvision version: 0.21.0+cu124\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"torchvision version:\", torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zt9H7lT1RrsF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KOT7b3zoIghH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# Import necessary libraries\n",
        "from PIL import Image as PILImage\n",
        "from IPython.display import Image, display\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, fasterrcnn_resnet50_fpn_v2\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import torchvision\n",
        "import random\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "\n",
        "\n",
        "class HomelessDataset(Dataset):\n",
        "    def __init__(self, data_dir, xml_files, transform=None, augmentation_type=\"basic\"):\n",
        "        self.data_dir = data_dir\n",
        "        self.xml_files = xml_files\n",
        "        self.transform = transform\n",
        "        self.augmentation_type = augmentation_type  # \"basic\" or \"mosaic_mixup\"\n",
        "        self.class_dict = {\n",
        "            'Homeless_People': 1,\n",
        "            'Homeless_Encampments': 2,\n",
        "            'Homeless_Homeless Cart': 3,\n",
        "            'Homeless_Homeless Bike': 4\n",
        "        }\n",
        "        # Initialize class counts per image for sampling\n",
        "        self.class_counts_per_image = self._count_classes_per_image()\n",
        "\n",
        "    def _count_classes_per_image(self):\n",
        "        \"\"\"Count the number of each class in each image for sampling weights\"\"\"\n",
        "        class_counts_per_image = []\n",
        "\n",
        "        for xml_file in self.xml_files:\n",
        "            xml_path = os.path.join(self.data_dir, xml_file)\n",
        "            try:\n",
        "                tree = ET.parse(xml_path)\n",
        "                root = tree.getroot()\n",
        "\n",
        "                # Initialize count dict for this image\n",
        "                counts = {1: 0, 2: 0, 3: 0, 4: 0}\n",
        "\n",
        "                # Count classes\n",
        "                for obj in root.findall('object'):\n",
        "                    class_name = obj.find('name').text\n",
        "                    if class_name in self.class_dict:\n",
        "                        class_id = self.class_dict[class_name]\n",
        "                        counts[class_id] += 1\n",
        "\n",
        "                class_counts_per_image.append(counts)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {xml_file}: {e}\")\n",
        "                # Add empty counts if there's an error\n",
        "                class_counts_per_image.append({1: 0, 2: 0, 3: 0, 4: 0})\n",
        "\n",
        "        return class_counts_per_image\n",
        "\n",
        "    def get_sample_weights(self, target_distribution=None):\n",
        "        \"\"\"\n",
        "        Calculate sample weights for each image based on classes present\n",
        "        If target_distribution is None, use uniform distribution\n",
        "        \"\"\"\n",
        "        # Default to uniform distribution\n",
        "        if target_distribution is None:\n",
        "            target_distribution = {1: 0.25, 2: 0.25, 3: 0.25, 4: 0.25}\n",
        "\n",
        "        # Count total instances by class\n",
        "        total_counts = {1: 0, 2: 0, 3: 0, 4: 0}\n",
        "        for counts in self.class_counts_per_image:\n",
        "            for cls, count in counts.items():\n",
        "                total_counts[cls] += count\n",
        "\n",
        "        # Calculate weights\n",
        "        weights = []\n",
        "        for counts in self.class_counts_per_image:\n",
        "            # Weight is sum of (target_pct / actual_pct) for each class in the image\n",
        "            weight = 0\n",
        "            for cls, count in counts.items():\n",
        "                if count > 0 and total_counts[cls] > 0:\n",
        "                    cls_weight = target_distribution[cls] / (total_counts[cls] / sum(total_counts.values()))\n",
        "                    weight += cls_weight * count\n",
        "\n",
        "            # If no objects, use average weight\n",
        "            if weight == 0:\n",
        "                weight = 1.0\n",
        "\n",
        "            weights.append(weight)\n",
        "\n",
        "        return weights\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xml_files)\n",
        "\n",
        "    def is_valid_box(self, box):\n",
        "        \"\"\"Check if a bounding box is valid (has positive height and width).\"\"\"\n",
        "        x1, y1, x2, y2 = box\n",
        "        return x2 > x1 and y2 > y1 and x2 - x1 >= 5 and y2 - y1 >= 5  # Minimum size check\n",
        "\n",
        "    def _get_image_and_targets(self, idx):\n",
        "        \"\"\"Helper function to get image and targets from XML\"\"\"\n",
        "        # Parse XML\n",
        "        xml_path = os.path.join(self.data_dir, self.xml_files[idx])\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Load image\n",
        "        img_name = root.find('filename').text\n",
        "        img_path = os.path.join(self.data_dir, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            # Fallback if image not found\n",
        "            print(f\"Warning: Image {img_name} not found, using placeholder\")\n",
        "            image = np.zeros((512, 512, 3), dtype=np.uint8)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Extract annotations\n",
        "        boxes = []\n",
        "        class_ids = []\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        for obj in root.findall('object'):\n",
        "            class_name = obj.find('name').text\n",
        "            if class_name not in self.class_dict:\n",
        "                continue\n",
        "\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = max(0, int(float(bbox.find('xmin').text)))\n",
        "            ymin = max(0, int(float(bbox.find('ymin').text)))\n",
        "            xmax = min(w, int(float(bbox.find('xmax').text)))\n",
        "            ymax = min(h, int(float(bbox.find('ymax').text)))\n",
        "\n",
        "            box = [xmin, ymin, xmax, ymax]\n",
        "\n",
        "            # Filter out invalid boxes\n",
        "            if self.is_valid_box(box):\n",
        "                boxes.append(box)\n",
        "                class_ids.append(self.class_dict[class_name])\n",
        "\n",
        "\n",
        "        return image, boxes, class_ids,(h, w)\n",
        "\n",
        "    def _apply_basic_transform(self, image, boxes, class_ids, img_shape):\n",
        "        h, w = img_shape\n",
        "        orig_h, orig_w = h, w  # Store original dimensions\n",
        "\n",
        "        # Apply image transforms\n",
        "        if self.transform:\n",
        "            image = PILImage.fromarray(image)  # Convert NumPy array (from cv2) to PIL\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image)\n",
        "\n",
        "        # Calculate scaling factors\n",
        "        new_h, new_w = 512, 512  # Your standard target size\n",
        "        h_scale = new_h / orig_h\n",
        "        w_scale = new_w / orig_w\n",
        "\n",
        "        # Handle case with no valid boxes\n",
        "        if len(boxes) == 0:\n",
        "            # Return dummy target\n",
        "            dummy_boxes = torch.FloatTensor([[0, 0, 10, 10]])\n",
        "            dummy_labels = torch.LongTensor([0])  # Background class\n",
        "\n",
        "            target = {\n",
        "                \"boxes\": dummy_boxes,\n",
        "                \"labels\": dummy_labels,\n",
        "                \"image_id\": torch.tensor([0]),\n",
        "                \"area\": torch.tensor([100.0]),\n",
        "                \"iscrowd\": torch.zeros((1,), dtype=torch.int64)\n",
        "            }\n",
        "\n",
        "            return image, target, False\n",
        "\n",
        "        # Scale boxes according to image resize\n",
        "        scaled_boxes = []\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = box\n",
        "            # Scale coordinates\n",
        "            x1 = int(x1 * w_scale)\n",
        "            y1 = int(y1 * h_scale)\n",
        "            x2 = int(x2 * w_scale)\n",
        "            y2 = int(y2 * h_scale)\n",
        "            # Ensure valid box\n",
        "            x1, y1 = max(0, x1), max(0, y1)\n",
        "            x2, y2 = min(new_w, x2), min(new_h, y2)\n",
        "            scaled_boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "        # Convert to PyTorch format\n",
        "        boxes = torch.FloatTensor(scaled_boxes)\n",
        "        labels = torch.LongTensor(class_ids)\n",
        "\n",
        "        # Calculate areas\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"image_id\": torch.tensor([0]),\n",
        "            \"area\": area,\n",
        "            \"iscrowd\": torch.zeros((len(boxes),), dtype=torch.int64)\n",
        "        }\n",
        "\n",
        "        return image, target, True  # True indicates a valid target\n",
        "\n",
        "    def _apply_mosaic_augmentation(self, idx):\n",
        "        \"\"\"Apply mosaic augmentation for detection only (no masks)\"\"\"\n",
        "        # Get current image and 3 random images without applying transformations yet\n",
        "        indices = [idx] + [random.randint(0, len(self.xml_files) - 1) for _ in range(3)]\n",
        "        raw_images = []\n",
        "        all_boxes = []\n",
        "        all_class_ids = []\n",
        "        all_shapes = []\n",
        "\n",
        "        # Load all raw images first\n",
        "        for mosaic_idx in indices:\n",
        "            image, boxes, class_ids, img_shape = self._get_image_and_targets(mosaic_idx)\n",
        "            raw_images.append(image)\n",
        "            all_boxes.append(boxes)\n",
        "            all_class_ids.append(class_ids)\n",
        "            all_shapes.append(img_shape)\n",
        "\n",
        "        # Create the mosaic canvas\n",
        "        mosaic_size = 512\n",
        "        mosaic_img = np.zeros((mosaic_size, mosaic_size, 3), dtype=np.uint8)\n",
        "\n",
        "        # Split points\n",
        "        cx, cy = mosaic_size // 2, mosaic_size // 2\n",
        "\n",
        "        # Combined boxes and labels for the mosaic\n",
        "        combined_boxes = []\n",
        "        combined_labels = []\n",
        "\n",
        "        # Fill in the mosaic with the 4 images and adjust their bounding boxes\n",
        "        placements = [(0, 0), (cx, 0), (0, cy), (cx, cy)]  # Top-left, top-right, bottom-left, bottom-right\n",
        "\n",
        "        for i in range(min(4, len(raw_images))):\n",
        "            image = raw_images[i]\n",
        "            boxes = all_boxes[i]\n",
        "            class_ids = all_class_ids[i]\n",
        "            h, w = all_shapes[i]\n",
        "\n",
        "            # Resize the image to fit in its quadrant\n",
        "            quadrant_w, quadrant_h = cx, cy\n",
        "            part_img = cv2.resize(image, (quadrant_w, quadrant_h))\n",
        "\n",
        "            # Place in the mosaic\n",
        "            x_offset, y_offset = placements[i]\n",
        "            mosaic_img[y_offset:y_offset+quadrant_h, x_offset:x_offset+quadrant_w] = part_img\n",
        "\n",
        "            # Scale and offset boxes\n",
        "            scale_x = quadrant_w / w\n",
        "            scale_y = quadrant_h / h\n",
        "\n",
        "            for box_idx, box in enumerate(boxes):\n",
        "                if len(box) == 4:  # Ensure the box has the expected format\n",
        "                    x1, y1, x2, y2 = box\n",
        "\n",
        "                    # Scale coordinates\n",
        "                    x1_new = int(x1 * scale_x) + x_offset\n",
        "                    y1_new = int(y1 * scale_y) + y_offset\n",
        "                    x2_new = int(x2 * scale_x) + x_offset\n",
        "                    y2_new = int(y2 * scale_y) + y_offset\n",
        "\n",
        "                    # Clip to mosaic boundaries\n",
        "                    x1_new = max(0, min(mosaic_size-1, x1_new))\n",
        "                    y1_new = max(0, min(mosaic_size-1, y1_new))\n",
        "                    x2_new = max(0, min(mosaic_size-1, x2_new))\n",
        "                    y2_new = max(0, min(mosaic_size-1, y2_new))\n",
        "\n",
        "                    # Check if the box is still valid\n",
        "                    if x2_new > x1_new and y2_new > y1_new and (x2_new - x1_new) >= 5 and (y2_new - y1_new) >= 5:\n",
        "                        combined_boxes.append([x1_new, y1_new, x2_new, y2_new])\n",
        "                        combined_labels.append(class_ids[box_idx])\n",
        "\n",
        "        # Apply transformations to the whole mosaic image at once\n",
        "        if self.transform:\n",
        "            # Convert to PIL Image first for the transform\n",
        "            mosaic_pil = PILImage.fromarray(mosaic_img)\n",
        "            transformed_img = self.transform(mosaic_pil)\n",
        "        else:\n",
        "            transformed_img = transforms.ToTensor()(mosaic_img)\n",
        "\n",
        "        # Handle case with no valid boxes\n",
        "        if len(combined_boxes) == 0:\n",
        "            dummy_boxes = torch.FloatTensor([[0, 0, 10, 10]])\n",
        "            dummy_labels = torch.LongTensor([0])  # Background class\n",
        "\n",
        "            target = {\n",
        "                \"boxes\": dummy_boxes,\n",
        "                \"labels\": dummy_labels,\n",
        "                \"image_id\": torch.tensor([idx]),\n",
        "                \"area\": torch.tensor([100.0]),\n",
        "                \"iscrowd\": torch.zeros((1,), dtype=torch.int64)\n",
        "            }\n",
        "            return transformed_img, target, False\n",
        "\n",
        "        # Convert to PyTorch format\n",
        "        boxes = torch.FloatTensor(combined_boxes)\n",
        "        labels = torch.LongTensor(combined_labels)\n",
        "\n",
        "        # Calculate areas\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        # Create final target\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"image_id\": torch.tensor([idx]),\n",
        "            \"area\": area,\n",
        "            \"iscrowd\": torch.zeros((len(boxes),), dtype=torch.int64)\n",
        "        }\n",
        "\n",
        "        return transformed_img, target, True\n",
        "\n",
        "    def _apply_mixup_augmentation(self, idx, alpha=0.5):\n",
        "        \"\"\"Apply mixup augmentation by blending two images and combining boxes intelligently\"\"\"\n",
        "        # Get two images without transforms first\n",
        "        idx2 = random.randint(0, len(self.xml_files) - 1)\n",
        "\n",
        "        # Get raw data\n",
        "        image1, boxes1, class_ids1, img_shape1 = self._get_image_and_targets(idx)\n",
        "        image2, boxes2, class_ids2, img_shape2 = self._get_image_and_targets(idx2)\n",
        "\n",
        "        # Resize both images to the same size before mixing\n",
        "        h, w = 512, 512\n",
        "        image1_resized = cv2.resize(image1, (w, h))\n",
        "        image2_resized = cv2.resize(image2, (w, h))\n",
        "\n",
        "        # Calculate scale factors to adjust bounding boxes\n",
        "        h1, w1 = img_shape1\n",
        "        h2, w2 = img_shape2\n",
        "\n",
        "        scale_x1, scale_y1 = w/w1, h/h1\n",
        "        scale_x2, scale_y2 = w/w2, h/h2\n",
        "\n",
        "        # Scale boxes for both images\n",
        "        scaled_boxes1 = []\n",
        "        for box in boxes1:\n",
        "            x1, y1, x2, y2 = box\n",
        "            x1s, y1s = int(x1 * scale_x1), int(y1 * scale_y1)\n",
        "            x2s, y2s = int(x2 * scale_x1), int(y2 * scale_y1)\n",
        "            # Clip to boundaries\n",
        "            x1s, y1s = max(0, x1s), max(0, y1s)\n",
        "            x2s, y2s = min(w, x2s), min(h, y2s)\n",
        "            # Check if valid\n",
        "            if x2s > x1s and y2s > y1s and (x2s - x1s) >= 5 and (y2s - y1s) >= 5:\n",
        "                scaled_boxes1.append([x1s, y1s, x2s, y2s])\n",
        "\n",
        "        scaled_boxes2 = []\n",
        "        for box in boxes2:\n",
        "            x1, y1, x2, y2 = box\n",
        "            x1s, y1s = int(x1 * scale_x2), int(y1 * scale_y2)\n",
        "            x2s, y2s = int(x2 * scale_x2), int(y2 * scale_y2)\n",
        "            # Clip to boundaries\n",
        "            x1s, y1s = max(0, x1s), max(0, y1s)\n",
        "            x2s, y2s = min(w, x2s), min(h, y2s)\n",
        "            # Check if valid\n",
        "            if x2s > x1s and y2s > y1s and (x2s - x1s) >= 5 and (y2s - y1s) >= 5:\n",
        "                scaled_boxes2.append([x1s, y1s, x2s, y2s])\n",
        "\n",
        "        # If either image has no valid boxes after scaling, fall back to basic transform\n",
        "        if not scaled_boxes1 and not scaled_boxes2:\n",
        "            return self._apply_basic_transform(image1, boxes1, class_ids1, img_shape1)\n",
        "\n",
        "        # Random mixup ratio from beta distribution\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "\n",
        "        # Blend the images\n",
        "        mixed_img_np = cv2.addWeighted(image1_resized, lam, image2_resized, 1 - lam, 0)\n",
        "\n",
        "        # Handle boxes based on mixup ratio\n",
        "        # This approach is smarter: if one image is dominant, we prioritize its boxes\n",
        "        combined_boxes = []\n",
        "        combined_labels = []\n",
        "\n",
        "        # If lambda > 0.7, prioritize boxes from image1\n",
        "        if lam > 0.7:\n",
        "            for i, box in enumerate(scaled_boxes1):\n",
        "                if i < len(class_ids1):\n",
        "                    combined_boxes.append(box)\n",
        "                    combined_labels.append(class_ids1[i])\n",
        "        # If lambda < 0.3, prioritize boxes from image2\n",
        "        elif lam < 0.3:\n",
        "            for i, box in enumerate(scaled_boxes2):\n",
        "                if i < len(class_ids2):\n",
        "                    combined_boxes.append(box)\n",
        "                    combined_labels.append(class_ids2[i])\n",
        "        # For balanced mix, use boxes from both images\n",
        "        else:\n",
        "            for i, box in enumerate(scaled_boxes1):\n",
        "                if i < len(class_ids1):\n",
        "                    combined_boxes.append(box)\n",
        "                    combined_labels.append(class_ids1[i])\n",
        "            for i, box in enumerate(scaled_boxes2):\n",
        "                if i < len(class_ids2):\n",
        "                    combined_boxes.append(box)\n",
        "                    combined_labels.append(class_ids2[i])\n",
        "\n",
        "        # Apply transform to the mixed image\n",
        "        if self.transform:\n",
        "            # Convert to PIL Image first for the transform\n",
        "            mixed_pil = PILImage.fromarray(mixed_img_np)\n",
        "            transformed_img = self.transform(mixed_pil)\n",
        "        else:\n",
        "            transformed_img = transforms.ToTensor()(mixed_img_np)\n",
        "\n",
        "        # Handle case with no valid boxes\n",
        "        if len(combined_boxes) == 0:\n",
        "            dummy_boxes = torch.FloatTensor([[0, 0, 10, 10]])\n",
        "            dummy_labels = torch.LongTensor([0])  # Background class\n",
        "\n",
        "            target = {\n",
        "                \"boxes\": dummy_boxes,\n",
        "                \"labels\": dummy_labels,\n",
        "                \"image_id\": torch.tensor([idx]),\n",
        "                \"area\": torch.tensor([100.0]),\n",
        "                \"iscrowd\": torch.zeros((1,), dtype=torch.int64)\n",
        "            }\n",
        "            return transformed_img, target, False\n",
        "\n",
        "        # Convert to PyTorch format\n",
        "        boxes = torch.FloatTensor(combined_boxes)\n",
        "        labels = torch.LongTensor(combined_labels)\n",
        "\n",
        "        # Calculate areas\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        # Create final target\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"image_id\": torch.tensor([idx]),\n",
        "            \"area\": area,\n",
        "            \"iscrowd\": torch.zeros((len(boxes),), dtype=torch.int64)\n",
        "        }\n",
        "\n",
        "        return transformed_img, target, True\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Get item with appropriate augmentation strategy\"\"\"\n",
        "        if self.augmentation_type == \"basic\":\n",
        "            # Basic augmentation\n",
        "            image, boxes, class_ids,img_shape = self._get_image_and_targets(idx)\n",
        "            return self._apply_basic_transform(image, boxes, class_ids,img_shape)\n",
        "        elif self.augmentation_type == \"mosaic_mixup\":\n",
        "            # Original implementation\n",
        "            p = random.random()\n",
        "            if p < 0.4:  # 40% just mosaic\n",
        "                return self._apply_mosaic_augmentation(idx)\n",
        "            elif p < 0.8:  # 40% mosaic+mixup\n",
        "                return self._apply_mixup_augmentation(idx)\n",
        "            else:  # 20% just basic\n",
        "                image, boxes, class_ids, img_shape = self._get_image_and_targets(idx)\n",
        "                return self._apply_basic_transform(image, boxes, class_ids, img_shape)\n",
        "        elif self.augmentation_type == \"mosaic_only\":\n",
        "            # 50% mosaic, 50% basic\n",
        "            p = random.random()\n",
        "            if p < 0.5:\n",
        "                return self._apply_mosaic_augmentation(idx)\n",
        "            else:\n",
        "                image, boxes, class_ids,img_shape = self._get_image_and_targets(idx)\n",
        "                return self._apply_basic_transform(image, boxes, class_ids, img_shape)\n",
        "\n",
        "def get_basic_transform(train):\n",
        "    if train:\n",
        "        return transforms.Compose([\n",
        "            # REMOVE transforms.ToPILImage(),\n",
        "            transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "            transforms.RandomHorizontalFlip(0.5),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            # REMOVE transforms.ToPILImage(),\n",
        "            transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "def get_model(num_classes):\n",
        "\n",
        "    model = fasterrcnn_resnet50_fpn_v2(pretrained=True)\n",
        "\n",
        "    # Replace the classifier head\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for detection-only tasks (no masks)\"\"\"\n",
        "    images = []\n",
        "    targets = []\n",
        "\n",
        "    for img, target, is_valid in batch:\n",
        "        if is_valid:\n",
        "            images.append(img)\n",
        "            targets.append(target)\n",
        "\n",
        "    if len(images) == 0:\n",
        "        dummy_img = torch.zeros((3, 512, 512))\n",
        "        dummy_target = {\n",
        "            \"boxes\": torch.FloatTensor([[0, 0, 10, 10]]),\n",
        "            \"labels\": torch.LongTensor([0]),\n",
        "            \"image_id\": torch.tensor([0]),\n",
        "            \"area\": torch.tensor([100.0]),\n",
        "            \"iscrowd\": torch.zeros((1,), dtype=torch.int64)\n",
        "        }\n",
        "        images = [dummy_img]\n",
        "        targets = [dummy_target]\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"Calculate IoU between two boxes\"\"\"\n",
        "    # Convert to coordinates format if needed\n",
        "    if isinstance(box1, torch.Tensor):\n",
        "        box1 = box1.cpu().numpy()\n",
        "    if isinstance(box2, torch.Tensor):\n",
        "        box2 = box2.cpu().numpy()\n",
        "\n",
        "    # Intersection coordinates\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    # Intersection area\n",
        "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "\n",
        "    # Union area\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union = box1_area + box2_area - intersection\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = intersection / max(union, 1e-6)\n",
        "\n",
        "    return iou\n",
        "\n",
        "def calculate_metrics(pred_boxes, pred_labels, pred_scores, gt_boxes, gt_labels, iou_threshold=0.6):\n",
        "    \"\"\"\n",
        "    Calculate mAP, IoU, and F1 scores for each class\n",
        "    \"\"\"\n",
        "    if len(gt_boxes) == 0:\n",
        "        if len(pred_boxes) == 0:\n",
        "            return {\n",
        "                \"mAP\": 1.0,\n",
        "                \"IoU\": 1.0,\n",
        "                \"class_metrics\": {\n",
        "                    cls: {\"precision\": 1.0, \"recall\": 1.0, \"f1\": 1.0, \"AP\": 1.0, \"IoU\": 1.0}\n",
        "                    for cls in range(1, 5)\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"mAP\": 0.0,\n",
        "                \"IoU\": 0.0,\n",
        "                \"class_metrics\": {\n",
        "                    cls: {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"AP\": 0.0, \"IoU\": 0.0}\n",
        "                    for cls in range(1, 5)\n",
        "                }\n",
        "            }\n",
        "\n",
        "    # Track metrics for each class\n",
        "    class_metrics = {}\n",
        "    overall_iou = 0.0\n",
        "    num_valid_ious = 0\n",
        "\n",
        "    # Process each class separately\n",
        "    for class_id in range(1, 5):  # 1-4 for the classes\n",
        "        # Get predictions and ground truth for this class\n",
        "        class_pred_indices = [i for i, lbl in enumerate(pred_labels) if lbl == class_id]\n",
        "        class_gt_indices = [i for i, lbl in enumerate(gt_labels) if lbl == class_id]\n",
        "\n",
        "        # Initialize class metrics\n",
        "        class_metrics[class_id] = {\n",
        "            \"precision\": 0.0,\n",
        "            \"recall\": 0.0,\n",
        "            \"f1\": 0.0,\n",
        "            \"AP\": 0.0,\n",
        "            \"IoU\": 0.0\n",
        "        }\n",
        "\n",
        "        if not class_gt_indices:  # No ground truth for this class\n",
        "            if not class_pred_indices:  # No predictions for this class either\n",
        "                class_metrics[class_id] = {\n",
        "                    \"precision\": 1.0,\n",
        "                    \"recall\": 1.0,\n",
        "                    \"f1\": 1.0,\n",
        "                    \"AP\": 1.0,\n",
        "                    \"IoU\": 1.0\n",
        "                }\n",
        "            # Otherwise all metrics stay at 0\n",
        "            continue\n",
        "\n",
        "        if not class_pred_indices:  # No predictions for this class\n",
        "            # All metrics stay at 0\n",
        "            continue\n",
        "\n",
        "        # Get boxes, scores for this class\n",
        "        c_pred_boxes = [pred_boxes[i] for i in class_pred_indices]\n",
        "        c_pred_scores = [pred_scores[i] for i in class_pred_indices]\n",
        "        c_gt_boxes = [gt_boxes[i] for i in class_gt_indices]\n",
        "\n",
        "        # Sort predictions by confidence\n",
        "        c_pred_boxes, c_pred_scores = zip(*sorted(zip(c_pred_boxes, c_pred_scores),\n",
        "                                              key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        # For metrics calculation\n",
        "        true_positives = np.zeros(len(c_pred_boxes))\n",
        "        false_positives = np.zeros(len(c_pred_boxes))\n",
        "        gt_matched = [False] * len(c_gt_boxes)\n",
        "\n",
        "        # Track IoUs for this class\n",
        "        class_ious = []\n",
        "\n",
        "        # Check each prediction\n",
        "        for pred_idx, pred_box in enumerate(c_pred_boxes):\n",
        "            # Find best matching ground truth\n",
        "            best_iou = 0\n",
        "            best_gt_idx = -1\n",
        "\n",
        "            for gt_idx, gt_box in enumerate(c_gt_boxes):\n",
        "                if gt_matched[gt_idx]:\n",
        "                    continue  # This gt already matched\n",
        "\n",
        "                iou = calculate_iou(pred_box, gt_box)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_gt_idx = gt_idx\n",
        "\n",
        "            # Store IoU for metrics\n",
        "            if best_iou > 0:\n",
        "                class_ious.append(best_iou)\n",
        "\n",
        "            # Check if we have a match\n",
        "            if best_iou >= iou_threshold:\n",
        "                if not gt_matched[best_gt_idx]:\n",
        "                    true_positives[pred_idx] = 1\n",
        "                    gt_matched[best_gt_idx] = True\n",
        "                else:\n",
        "                    false_positives[pred_idx] = 1\n",
        "            else:\n",
        "                false_positives[pred_idx] = 1\n",
        "\n",
        "        # Compute cumulative values\n",
        "        cumsum_tp = np.cumsum(true_positives)\n",
        "        cumsum_fp = np.cumsum(false_positives)\n",
        "\n",
        "        # Calculate precision and recall\n",
        "        precision = cumsum_tp / (cumsum_tp + cumsum_fp + 1e-10)\n",
        "        recall = cumsum_tp / len(c_gt_boxes)\n",
        "\n",
        "        # Compute average precision using the 11-point interpolation\n",
        "        ap = 0\n",
        "        for r in np.arange(0, 1.1, 0.1):\n",
        "            if np.sum(recall >= r) == 0:\n",
        "                p = 0\n",
        "            else:\n",
        "                p = np.max(precision[recall >= r])\n",
        "            ap += p / 11\n",
        "\n",
        "        # Calculate F1 score\n",
        "        if len(precision) > 0 and len(recall) > 0:\n",
        "            f1 = 2 * (precision[-1] * recall[-1]) / (precision[-1] + recall[-1] + 1e-10)\n",
        "        else:\n",
        "            f1 = 0.0\n",
        "\n",
        "        # Calculate average IoU for this class\n",
        "        avg_iou = np.mean(class_ious) if class_ious else 0.0\n",
        "\n",
        "        # Store metrics for this class\n",
        "        class_metrics[class_id] = {\n",
        "            \"precision\": float(precision[-1]) if len(precision) > 0 else 0.0,\n",
        "            \"recall\": float(recall[-1]) if len(recall) > 0 else 0.0,\n",
        "            \"f1\": float(f1),\n",
        "            \"AP\": float(ap),\n",
        "            \"IoU\": float(avg_iou)\n",
        "        }\n",
        "\n",
        "        # Update overall IoU\n",
        "        if avg_iou > 0:\n",
        "            overall_iou += avg_iou\n",
        "            num_valid_ious += 1\n",
        "\n",
        "    # Calculate mAP across all classes\n",
        "    mAP = sum(class_metrics[cls][\"AP\"] for cls in class_metrics) / len(class_metrics)\n",
        "\n",
        "    # Calculate overall IoU\n",
        "    overall_iou = overall_iou / max(1, num_valid_ious)\n",
        "\n",
        "    # Return all metrics\n",
        "    return {\n",
        "        \"mAP\": float(mAP),\n",
        "        \"IoU\": float(overall_iou),\n",
        "        \"class_metrics\": class_metrics\n",
        "    }\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10):\n",
        "    \"\"\"Basic training for one epoch without loss reweighting\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Warmup scheduler for first epoch\n",
        "    lr_scheduler = None\n",
        "    if epoch == 0:\n",
        "        warmup_factor = 1.0 / 1000\n",
        "        warmup_iters = min(1000, len(data_loader) - 1)\n",
        "        lr_scheduler = optim.lr_scheduler.LinearLR(\n",
        "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
        "        )\n",
        "\n",
        "    for i, (images, targets) in enumerate(data_loader):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Forward pass and get loss\n",
        "        loss_dict = model(images, targets)\n",
        "\n",
        "        # Sum losses\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # Handle NaN loss\n",
        "        if not torch.isfinite(losses):\n",
        "            print(f\"Loss is {losses}, skipping batch\")\n",
        "            optimizer.zero_grad()\n",
        "            continue\n",
        "\n",
        "        # Backprop\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "\n",
        "        # Gradient clipping for stability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update LR if needed\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        # Track loss\n",
        "        running_loss += losses.item()\n",
        "\n",
        "        # Print progress\n",
        "        if i % print_freq == 0:\n",
        "            print(f\"Epoch {epoch}, Batch {i}/{len(data_loader)}, Loss: {losses.item():.4f}\")\n",
        "\n",
        "    return running_loss / len(data_loader)\n",
        "\n",
        "def train_one_epoch_reweighed(model, optimizer, data_loader, device, epoch, class_weights, print_freq=10):\n",
        "    \"\"\"Custom version of train_one_epoch that applies class weights to the classification loss\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Warmup scheduler\n",
        "    lr_scheduler = None\n",
        "    if epoch == 0:\n",
        "        warmup_factor = 1.0 / 1000\n",
        "        warmup_iters = min(1000, len(data_loader) - 1)\n",
        "        lr_scheduler = optim.lr_scheduler.LinearLR(\n",
        "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
        "        )\n",
        "\n",
        "    for i, (images, targets) in enumerate(data_loader):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Forward pass and get loss\n",
        "        loss_dict = model(images, targets)\n",
        "\n",
        "        # Apply class weights to classification loss\n",
        "        if \"loss_classifier\" in loss_dict:\n",
        "            # Get all target labels from this batch\n",
        "            batch_labels = []\n",
        "            for t in targets:\n",
        "                batch_labels.extend(t[\"labels\"].cpu().numpy())\n",
        "\n",
        "            # Calculate a weighted factor based on labels in this batch\n",
        "            if batch_labels:\n",
        "                weight_factor = 0\n",
        "                for label in batch_labels:\n",
        "                    weight_factor += class_weights.get(label, 1.0)\n",
        "                weight_factor /= len(batch_labels)\n",
        "\n",
        "                # Apply weight to classification loss\n",
        "                loss_dict[\"loss_classifier\"] *= weight_factor\n",
        "\n",
        "        # Sum losses\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # Handle NaN loss\n",
        "        if not torch.isfinite(losses):\n",
        "            print(f\"Loss is {losses}, skipping batch\")\n",
        "            optimizer.zero_grad()\n",
        "            continue\n",
        "\n",
        "        # Backprop\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "\n",
        "        # Gradient clipping for stability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update LR if needed\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        # Track loss\n",
        "        running_loss += losses.item()\n",
        "\n",
        "        # Print progress\n",
        "        if i % print_freq == 0:\n",
        "            print(f\"Epoch {epoch}, Batch {i}/{len(data_loader)}, Loss: {losses.item():.4f}\")\n",
        "\n",
        "    return running_loss / len(data_loader)\n",
        "\n",
        "def evaluate_model(model, data_loader, device):\n",
        "    \"\"\"Evaluate model with comprehensive metrics\"\"\"\n",
        "    model.eval()\n",
        "    metrics_accumulator = {\n",
        "        \"mAP\": [],\n",
        "        \"IoU\": [],\n",
        "        \"class_metrics\": {\n",
        "            1: {\"precision\": [], \"recall\": [], \"f1\": [], \"AP\": [], \"IoU\": []},\n",
        "            2: {\"precision\": [], \"recall\": [], \"f1\": [], \"AP\": [], \"IoU\": []},\n",
        "            3: {\"precision\": [], \"recall\": [], \"f1\": [], \"AP\": [], \"IoU\": []},\n",
        "            4: {\"precision\": [], \"recall\": [], \"f1\": [], \"AP\": [], \"IoU\": []}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            # Standard inference\n",
        "            results = model(images)\n",
        "\n",
        "            # Calculate metrics for each image\n",
        "            for i, (result, target) in enumerate(zip(results, targets)):\n",
        "                pred_boxes = result['boxes'].cpu()\n",
        "                pred_labels = result['labels'].cpu()\n",
        "                pred_scores = result['scores'].cpu()\n",
        "\n",
        "                gt_boxes = target['boxes'].cpu()\n",
        "                gt_labels = target['labels'].cpu()\n",
        "\n",
        "                # Calculate all metrics\n",
        "                metrics = calculate_metrics(\n",
        "                    pred_boxes, pred_labels, pred_scores,\n",
        "                    gt_boxes, gt_labels, iou_threshold=0.5\n",
        "                )\n",
        "\n",
        "                # Accumulate metrics\n",
        "                metrics_accumulator[\"mAP\"].append(metrics[\"mAP\"])\n",
        "                metrics_accumulator[\"IoU\"].append(metrics[\"IoU\"])\n",
        "\n",
        "                # Accumulate class-specific metrics\n",
        "                for cls in range(1, 5):\n",
        "                    if cls in metrics[\"class_metrics\"]:\n",
        "                        for metric_name, value in metrics[\"class_metrics\"][cls].items():\n",
        "                            metrics_accumulator[\"class_metrics\"][cls][metric_name].append(value)\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_metrics = {\n",
        "        \"mAP\": np.mean(metrics_accumulator[\"mAP\"]) if metrics_accumulator[\"mAP\"] else 0.0,\n",
        "        \"IoU\": np.mean(metrics_accumulator[\"IoU\"]) if metrics_accumulator[\"IoU\"] else 0.0,\n",
        "        \"class_metrics\": {}\n",
        "    }\n",
        "\n",
        "    # Calculate class averages\n",
        "    for cls in range(1, 5):\n",
        "        avg_metrics[\"class_metrics\"][cls] = {}\n",
        "        for metric_name in [\"precision\", \"recall\", \"f1\", \"AP\", \"IoU\"]:\n",
        "            values = metrics_accumulator[\"class_metrics\"][cls][metric_name]\n",
        "            avg_metrics[\"class_metrics\"][cls][metric_name] = np.mean(values) if values else 0.0\n",
        "\n",
        "    return avg_metrics\n",
        "\n",
        "def visualize_predictions(model, dataset, device, num_images=5, confidence_thresholds=None, save_path=None):\n",
        "    \"\"\"\n",
        "    Visualize model predictions with class-specific confidence thresholds\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained model\n",
        "    - dataset: Dataset containing validation images\n",
        "    - device: Device to run inference on\n",
        "    - num_images: Number of images to visualize\n",
        "    - confidence_thresholds: Dictionary mapping class IDs to confidence thresholds\n",
        "    - save_path: Path to save visualization (if None, uses default name)\n",
        "\n",
        "    Returns:\n",
        "    - Path to saved visualization\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Default confidence thresholds if none provided\n",
        "    if confidence_thresholds is None:\n",
        "        confidence_thresholds = {1: 0.55, 2: 0.8, 3: 0.45, 4: 0.65}\n",
        "\n",
        "    # Class names and colors for display\n",
        "    class_names = {\n",
        "        1: 'People',\n",
        "        2: 'Encampments',\n",
        "        3: 'Cart',\n",
        "        4: 'Bike'\n",
        "    }\n",
        "\n",
        "    print(f\"Using confidence thresholds: {confidence_thresholds}\")\n",
        "\n",
        "    class_colors = {\n",
        "        1: (255, 0, 0),    # Red for people\n",
        "        2: (0, 255, 0),    # Green for encampments\n",
        "        3: (0, 0, 255),    # Blue for carts\n",
        "        4: (255, 255, 0)   # Yellow for bikes\n",
        "    }\n",
        "\n",
        "    # Get random samples\n",
        "    indices = np.random.choice(len(dataset), min(num_images, len(dataset)), replace=False)\n",
        "\n",
        "    plt.figure(figsize=(20, 20))\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        img, target, valid = dataset[idx]\n",
        "        if not valid:\n",
        "            continue\n",
        "\n",
        "        # Simple inference\n",
        "        with torch.no_grad():\n",
        "            prediction = model([img.to(device)])[0]\n",
        "\n",
        "        print(f\"\\nImage {idx} detection scores:\")\n",
        "        for class_id in range(1, 5):\n",
        "            scores = [prediction['scores'][j].item() for j in range(len(prediction['scores']))\n",
        "                      if prediction['labels'][j].item() == class_id]\n",
        "            print(f\"Class {class_id} ({class_names[class_id]}): {scores}\")\n",
        "\n",
        "        # Apply class-specific confidence thresholds\n",
        "        keep_indices = []\n",
        "        for j, label in enumerate(prediction['labels']):\n",
        "            label_id = label.item()\n",
        "            if prediction['scores'][j] >= confidence_thresholds.get(label_id, 0.5):\n",
        "                keep_indices.append(j)\n",
        "\n",
        "\n",
        "        # Replace with this more careful conversion\n",
        "        boxes = prediction['boxes'][keep_indices].cpu().numpy()\n",
        "        # Ensure boxes are within image boundaries before converting to int\n",
        "        boxes[:, 0] = np.clip(boxes[:, 0], 0, img.shape[2] - 1)\n",
        "        boxes[:, 1] = np.clip(boxes[:, 1], 0, img.shape[1] - 1)\n",
        "        boxes[:, 2] = np.clip(boxes[:, 2], 0, img.shape[2] - 1)\n",
        "        boxes[:, 3] = np.clip(boxes[:, 3], 0, img.shape[1] - 1)\n",
        "        boxes = boxes.astype(np.int32)\n",
        "        labels = prediction['labels'][keep_indices].cpu().numpy()\n",
        "        scores = prediction['scores'][keep_indices].cpu().numpy()\n",
        "\n",
        "        # Convert image back to numpy for display\n",
        "        image_np = img.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "        # Denormalize\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image_np = std * image_np + mean\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Create a copy for drawing\n",
        "        image_with_boxes = image_np.copy()\n",
        "\n",
        "        # Draw ground truth boxes\n",
        "        gt_boxes = target['boxes'].cpu().numpy().astype(np.int32)\n",
        "        gt_labels = target['labels'].cpu().numpy()\n",
        "\n",
        "        # Draw ground truth first\n",
        "        for box, label in zip(gt_boxes, gt_labels):\n",
        "            color = class_colors.get(label.item(), (255, 255, 255))\n",
        "            cv2.rectangle(image_with_boxes, (box[0], box[1]), (box[2], box[3]),\n",
        "                         color, 2, cv2.LINE_AA)\n",
        "            cv2.putText(image_with_boxes, f\"GT: {class_names.get(label.item(), 'Unknown')}\",\n",
        "                       (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Draw predictions\n",
        "        for box, label, score in zip(boxes, labels, scores):\n",
        "            color = class_colors.get(label.item(), (255, 255, 255))\n",
        "            cv2.rectangle(image_with_boxes, (box[0], box[1]), (box[2], box[3]),\n",
        "                         color, 2, cv2.LINE_AA)\n",
        "            cv2.putText(image_with_boxes,\n",
        "                       f\"{class_names.get(label.item(), 'Unknown')}: {score:.2f}\",\n",
        "                       (box[0], box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Display\n",
        "        plt.subplot(num_images, 1, i + 1)\n",
        "        plt.imshow(image_with_boxes)\n",
        "        plt.title(f\"Sample {idx} (Inference with Class-Specific Thresholds)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path is None:\n",
        "        save_path = \"mask_rcnn_predictions.png\"\n",
        "\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "    return save_path\n",
        "\n",
        "\n",
        "def plot_training_history(experiment_results, save_path=\"training_history.png\"):\n",
        "    \"\"\"\n",
        "    Plot training history comparing multiple experiments\n",
        "\n",
        "    Parameters:\n",
        "    - experiment_results: List of dictionaries containing experiment results\n",
        "    - save_path: Path to save the plot\n",
        "\n",
        "    Returns:\n",
        "    - Path to the saved plot\n",
        "    \"\"\"\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('Training Results Comparison', fontsize=16)\n",
        "\n",
        "    # Colors for different experiments\n",
        "    colors = ['b', 'r', 'g', 'c']\n",
        "\n",
        "    # Plot training loss\n",
        "    ax = axs[0, 0]\n",
        "    for i, result in enumerate(experiment_results):\n",
        "        ax.plot(result[\"history\"][\"train_loss\"],\n",
        "                label=f\"{result['experiment_name']}\",\n",
        "                color=colors[i])\n",
        "    ax.set_title('Training Loss')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.legend()\n",
        "\n",
        "    # Plot validation mAP\n",
        "    ax = axs[0, 1]\n",
        "    for i, result in enumerate(experiment_results):\n",
        "        ax.plot(result[\"history\"][\"val_mAP\"],\n",
        "                label=f\"{result['experiment_name']}\",\n",
        "                color=colors[i])\n",
        "    ax.set_title('Validation mAP')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('mAP')\n",
        "    ax.legend()\n",
        "\n",
        "    # Plot validation IoU\n",
        "    ax = axs[0, 2]\n",
        "    for i, result in enumerate(experiment_results):\n",
        "        ax.plot(result[\"history\"][\"val_IoU\"],\n",
        "                label=f\"{result['experiment_name']}\",\n",
        "                color=colors[i])\n",
        "    ax.set_title('Validation IoU')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('IoU')\n",
        "    ax.legend()\n",
        "\n",
        "    # Plot class F1 scores\n",
        "    class_names = {1: 'People', 2: 'Encampments', 3: 'Cart', 4: 'Bike'}\n",
        "    class_metrics = ['f1', 'AP', 'IoU']\n",
        "    metric_idx = 0  # F1 score\n",
        "\n",
        "    ax = axs[1, 0]\n",
        "    for cls in range(1, 5):\n",
        "        ax.plot([], [], label=class_names[cls], color=f'C{cls}')\n",
        "    for i, result in enumerate(experiment_results):\n",
        "        linestyle = '-' if i % 2 == 0 else '--'\n",
        "        for cls in range(1, 5):\n",
        "            ax.plot(result[\"history\"][\"class_metrics\"][cls][\"f1\"],\n",
        "                    color=f'C{cls}', linestyle=linestyle, alpha=0.7)\n",
        "    ax.set_title(f'Class F1 Scores')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('F1 Score')\n",
        "    ax.legend()\n",
        "\n",
        "    # Plot class AP scores\n",
        "    ax = axs[1, 1]\n",
        "    for i, result in enumerate(experiment_results):\n",
        "        for cls in range(1, 5):\n",
        "            ax.plot(result[\"history\"][\"class_metrics\"][cls][\"AP\"],\n",
        "                    label=f\"{class_names[cls]} - {result['experiment_name']}\" if i == 0 else \"\",\n",
        "                    color=f'C{cls}', linestyle='-' if i % 2 == 0 else '--', alpha=0.7)\n",
        "    ax.set_title('Class AP Scores')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('AP')\n",
        "    ax.legend()\n",
        "\n",
        "    # Plot class IoU scores\n",
        "    ax = axs[1, 2]\n",
        "    for i, result in enumerate(experiment_results):\n",
        "        for cls in range(1, 5):\n",
        "            ax.plot(result[\"history\"][\"class_metrics\"][cls][\"IoU\"],\n",
        "                    label=f\"{class_names[cls]} - {result['experiment_name']}\" if i == 0 else \"\",\n",
        "                    color=f'C{cls}', linestyle='-' if i % 2 == 0 else '--', alpha=0.7)\n",
        "    ax.set_title('Class IoU Scores')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('IoU')\n",
        "    ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "    return save_path\n",
        "\n",
        "def visualize_augmentations_with_boxes(data_dir, xml_files, transform=None):\n",
        "    \"\"\"\n",
        "    Visualize data augmentation techniques with bounding boxes for all types\n",
        "\n",
        "    Parameters:\n",
        "    - data_dir: Directory containing images and XML files\n",
        "    - xml_files: List of XML files\n",
        "    - transform: Optional transform to apply\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    # Create a dataset just for visualization\n",
        "    viz_dataset = HomelessDataset(\n",
        "        data_dir,\n",
        "        xml_files[:50],  # Use a subset\n",
        "        transform=None,  # Important: don't normalize during visualization\n",
        "        augmentation_type=\"basic\"\n",
        "    )\n",
        "\n",
        "    # Pick a random index with objects\n",
        "    for _ in range(10):  # Try up to 10 random indices\n",
        "        idx = np.random.randint(0, len(viz_dataset))\n",
        "        raw_image, boxes, class_ids, img_shape = viz_dataset._get_image_and_targets(idx)\n",
        "        if len(boxes) > 0:\n",
        "            break\n",
        "\n",
        "    # Define class colors\n",
        "    class_colors = {\n",
        "        1: (0, 255, 0),     # Green for People\n",
        "        2: (0, 0, 255),     # Blue for Encampments\n",
        "        3: (255, 0, 0),     # Red for Cart\n",
        "        4: (255, 255, 0)    # Yellow for Bike\n",
        "    }\n",
        "\n",
        "    class_names = {\n",
        "        1: 'People',\n",
        "        2: 'Encampments',\n",
        "        3: 'Cart',\n",
        "        4: 'Bike'\n",
        "    }\n",
        "\n",
        "    # 1. Show basic image with boxes\n",
        "    plt.subplot(3, 1, 1)\n",
        "    image_with_boxes = raw_image.copy()\n",
        "    for box, class_id in zip(boxes, class_ids):\n",
        "        x1, y1, x2, y2 = box\n",
        "        color = class_colors.get(class_id, (255, 255, 255))\n",
        "        cv2.rectangle(image_with_boxes, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(image_with_boxes, class_names.get(class_id, \"Unknown\"),\n",
        "                   (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    plt.imshow(image_with_boxes)\n",
        "    plt.title(\"Basic (No Augmentation)\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 2. Show mosaic augmentation with boxes\n",
        "    plt.subplot(3, 1, 2)\n",
        "\n",
        "    # Create a direct mosaic\n",
        "    indices = [idx] + [random.randint(0, len(viz_dataset.xml_files) - 1) for _ in range(3)]\n",
        "    mosaic_img = np.zeros((512, 512, 3), dtype=np.uint8)\n",
        "\n",
        "    # For tracking transformed boxes\n",
        "    mosaic_boxes = []\n",
        "    mosaic_class_ids = []\n",
        "\n",
        "    # Place images in mosaic grid (2x2)\n",
        "    cx, cy = 256, 256  # Center point\n",
        "    placements = [(0, 0), (cx, 0), (0, cy), (cx, cy)]  # Top-left, top-right, bottom-left, bottom-right\n",
        "\n",
        "    for i, mosaic_idx in enumerate(indices):\n",
        "        img, img_boxes, img_class_ids, img_shape = viz_dataset._get_image_and_targets(mosaic_idx)\n",
        "        h, w = img_shape\n",
        "\n",
        "        # Place in the mosaic\n",
        "        x_offset, y_offset = placements[i]\n",
        "\n",
        "        # Resize image to fit quadrant\n",
        "        quadrant_w, quadrant_h = cx, cy\n",
        "        part_img = cv2.resize(img, (quadrant_w, quadrant_h))\n",
        "        mosaic_img[y_offset:y_offset+quadrant_h, x_offset:x_offset+quadrant_w] = part_img\n",
        "\n",
        "        # Scale and offset boxes\n",
        "        scale_x = quadrant_w / w\n",
        "        scale_y = quadrant_h / h\n",
        "\n",
        "        for box_idx, box in enumerate(img_boxes):\n",
        "            if len(box) == 4:  # Ensure the box has the expected format\n",
        "                x1, y1, x2, y2 = box\n",
        "\n",
        "                # Scale coordinates\n",
        "                x1_new = int(x1 * scale_x) + x_offset\n",
        "                y1_new = int(y1 * scale_y) + y_offset\n",
        "                x2_new = int(x2 * scale_x) + x_offset\n",
        "                y2_new = int(y2 * scale_y) + y_offset\n",
        "\n",
        "                # Clip to mosaic boundaries\n",
        "                x1_new = max(0, min(512-1, x1_new))\n",
        "                y1_new = max(0, min(512-1, y1_new))\n",
        "                x2_new = max(0, min(512-1, x2_new))\n",
        "                y2_new = max(0, min(512-1, y2_new))\n",
        "\n",
        "                # Check if the box is still valid\n",
        "                if x2_new > x1_new and y2_new > y1_new and (x2_new - x1_new) >= 5 and (y2_new - y1_new) >= 5:\n",
        "                    mosaic_boxes.append([x1_new, y1_new, x2_new, y2_new])\n",
        "                    if box_idx < len(img_class_ids):\n",
        "                        mosaic_class_ids.append(img_class_ids[box_idx])\n",
        "                    else:\n",
        "                        mosaic_class_ids.append(1)  # Default to class 1 if out of bounds\n",
        "\n",
        "    # Draw boxes on mosaic\n",
        "    mosaic_with_boxes = mosaic_img.copy()\n",
        "    for box, class_id in zip(mosaic_boxes, mosaic_class_ids):\n",
        "        x1, y1, x2, y2 = box\n",
        "        color = class_colors.get(class_id, (255, 255, 255))\n",
        "        cv2.rectangle(mosaic_with_boxes, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(mosaic_with_boxes, class_names.get(class_id, \"Unknown\"),\n",
        "                   (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    plt.imshow(mosaic_with_boxes)\n",
        "    plt.title(\"Mosaic Augmentation\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 3. Show mixup augmentation with boxes\n",
        "    plt.subplot(3, 1, 3)\n",
        "\n",
        "    # Create a direct mixup without normalization for visualization\n",
        "    idx2 = random.randint(0, len(viz_dataset.xml_files) - 1)\n",
        "    img1, boxes1, class_ids1, img_shape1 = viz_dataset._get_image_and_targets(idx)\n",
        "    img2, boxes2, class_ids2, img_shape2 = viz_dataset._get_image_and_targets(idx2)\n",
        "\n",
        "    # Resize both images to the same size\n",
        "    h, w = 512, 512\n",
        "    img1_resized = cv2.resize(img1, (w, h))\n",
        "    img2_resized = cv2.resize(img2, (w, h))\n",
        "\n",
        "    # Calculate scale factors to adjust bounding boxes\n",
        "    h1, w1 = img_shape1\n",
        "    h2, w2 = img_shape2\n",
        "\n",
        "    scale_x1, scale_y1 = w/w1, h/h1\n",
        "    scale_x2, scale_y2 = w/w2, h/h2\n",
        "\n",
        "    # Scale boxes for both images\n",
        "    scaled_boxes1 = []\n",
        "    scaled_class_ids1 = []\n",
        "    for box_idx, box in enumerate(boxes1):\n",
        "        x1, y1, x2, y2 = box\n",
        "        x1s, y1s = int(x1 * scale_x1), int(y1 * scale_y1)\n",
        "        x2s, y2s = int(x2 * scale_x1), int(y2 * scale_y1)\n",
        "        # Clip to boundaries\n",
        "        x1s, y1s = max(0, x1s), max(0, y1s)\n",
        "        x2s, y2s = min(w, x2s), min(h, y2s)\n",
        "        # Check if valid\n",
        "        if x2s > x1s and y2s > y1s and (x2s - x1s) >= 5 and (y2s - y1s) >= 5:\n",
        "            scaled_boxes1.append([x1s, y1s, x2s, y2s])\n",
        "            if box_idx < len(class_ids1):\n",
        "                scaled_class_ids1.append(class_ids1[box_idx])\n",
        "\n",
        "    scaled_boxes2 = []\n",
        "    scaled_class_ids2 = []\n",
        "    for box_idx, box in enumerate(boxes2):\n",
        "        x1, y1, x2, y2 = box\n",
        "        x1s, y1s = int(x1 * scale_x2), int(y1 * scale_y2)\n",
        "        x2s, y2s = int(x2 * scale_x2), int(y2 * scale_y2)\n",
        "        # Clip to boundaries\n",
        "        x1s, y1s = max(0, x1s), max(0, y1s)\n",
        "        x2s, y2s = min(w, x2s), min(h, y2s)\n",
        "        # Check if valid\n",
        "        if x2s > x1s and y2s > y1s and (x2s - x1s) >= 5 and (y2s - y1s) >= 5:\n",
        "            scaled_boxes2.append([x1s, y1s, x2s, y2s])\n",
        "            if box_idx < len(class_ids2):\n",
        "                scaled_class_ids2.append(class_ids2[box_idx])\n",
        "\n",
        "    # Mix the images with a fixed alpha for visualization clarity\n",
        "    alpha = 0.5\n",
        "    mixed_img = cv2.addWeighted(img1_resized, alpha, img2_resized, 1.0 - alpha, 0)\n",
        "\n",
        "    # Draw boxes from both images\n",
        "    mixed_with_boxes = mixed_img.copy()\n",
        "\n",
        "    # Draw boxes from first image with solid lines\n",
        "    for box, class_id in zip(scaled_boxes1, scaled_class_ids1):\n",
        "        x1, y1, x2, y2 = box\n",
        "        color = class_colors.get(class_id, (255, 255, 255))\n",
        "        cv2.rectangle(mixed_with_boxes, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(mixed_with_boxes, f\"{class_names.get(class_id, 'Unknown')} (img1)\",\n",
        "                   (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    # Draw boxes from second image with dashed lines (to distinguish them)\n",
        "    for box, class_id in zip(scaled_boxes2, scaled_class_ids2):\n",
        "        x1, y1, x2, y2 = box\n",
        "        color = class_colors.get(class_id, (255, 255, 255))\n",
        "\n",
        "        # Create dashed line effect (crude but effective for visualization)\n",
        "        for i in range(x1, x2, 5):\n",
        "            cv2.line(mixed_with_boxes, (i, y1), (min(i+3, x2), y1), color, 2)\n",
        "            cv2.line(mixed_with_boxes, (i, y2), (min(i+3, x2), y2), color, 2)\n",
        "        for i in range(y1, y2, 5):\n",
        "            cv2.line(mixed_with_boxes, (x1, i), (x1, min(i+3, y2)), color, 2)\n",
        "            cv2.line(mixed_with_boxes, (x2, i), (x2, min(i+3, y2)), color, 2)\n",
        "\n",
        "        cv2.putText(mixed_with_boxes, f\"{class_names.get(class_id, 'Unknown')} (img2)\",\n",
        "                   (x1, y2+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    plt.imshow(mixed_with_boxes)\n",
        "    plt.title(\"Mixup Augmentation\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"augmentation_examples_with_boxes.png\")\n",
        "    plt.close()\n",
        "\n",
        "    return \"augmentation_examples_with_boxes.png\"\n",
        "\n",
        "\n",
        "def grid_search_thresholds(data_dir, train_xml_files, val_xml_files, num_epochs=5):\n",
        "    \"\"\"\n",
        "    Perform grid search to find optimal confidence thresholds for each class.\n",
        "\n",
        "    Parameters:\n",
        "    - data_dir: Directory containing images and XML files\n",
        "    - train_xml_files: List of XML files for training\n",
        "    - val_xml_files: List of XML files for validation\n",
        "    - num_epochs: Number of training epochs for the grid search model\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary with optimal confidence thresholds for each class\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"GRID SEARCH FOR OPTIMAL CONFIDENCE THRESHOLDS\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Create datasets (basic augmentation, no special sampling)\n",
        "    train_dataset = HomelessDataset(data_dir, train_xml_files,\n",
        "                                  transform=get_basic_transform(train=True),\n",
        "                                  augmentation_type=\"basic\")\n",
        "    val_dataset = HomelessDataset(data_dir, val_xml_files,\n",
        "                                transform=get_basic_transform(train=False),\n",
        "                                augmentation_type=\"basic\")\n",
        "\n",
        "    print(f\"Training samples: {len(train_dataset)}\")\n",
        "    print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "    # Create data loaders (random sampling)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    num_classes = 5  # Background + 4 classes\n",
        "    model = get_model(num_classes)\n",
        "    model.to(device)\n",
        "\n",
        "    # Use SGD optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(\n",
        "        params,\n",
        "        lr=0.005,\n",
        "        momentum=0.9,\n",
        "        weight_decay=0.0005\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler - cosine annealing\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max=num_epochs,\n",
        "        eta_min=1e-6\n",
        "    )\n",
        "\n",
        "    # Train the model for a few epochs\n",
        "    print(\"\\nTraining model for grid search...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_one_epoch(\n",
        "            model, optimizer, train_loader, device, epoch, print_freq=10\n",
        "        )\n",
        "\n",
        "        # Step LR scheduler\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Save the model\n",
        "    grid_search_model_path = \"grid_search_model.pth\"\n",
        "    torch.save(model.state_dict(), grid_search_model_path)\n",
        "    print(f\"Model saved to {grid_search_model_path}\")\n",
        "\n",
        "    # Set up grid search ranges for thresholds\n",
        "    threshold_ranges = {\n",
        "        1: np.arange(0.3, 0.8, 0.05),  # People\n",
        "        2: np.arange(0.3, 0.9, 0.05),  # Encampments\n",
        "        3: np.arange(0.3, 0.8, 0.05),  # Cart\n",
        "        4: np.arange(0.3, 0.8, 0.05)   # Bike\n",
        "    }\n",
        "\n",
        "    # Class names for display\n",
        "    class_names = {\n",
        "        1: 'People',\n",
        "        2: 'Encampments',\n",
        "        3: 'Cart',\n",
        "        4: 'Bike'\n",
        "    }\n",
        "\n",
        "    # Initialize best thresholds and metrics\n",
        "    best_thresholds = {cls: 0.5 for cls in range(1, 5)}\n",
        "    best_metrics = {cls: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'AP': 0.0} for cls in range(1, 5)}\n",
        "\n",
        "    # Grid search for each class separately\n",
        "    model.eval()\n",
        "\n",
        "    for class_id in range(1, 5):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"GRID SEARCH FOR CLASS {class_id} ({class_names[class_id]})\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        print(f\"{'Threshold':<10} {'Precision':<10} {'Recall':<10} {'F1':<10} {'AP':<10}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Keep other thresholds fixed at 0.5 (will optimize later)\n",
        "        current_thresholds = {cls: 0.5 for cls in range(1, 5)}\n",
        "\n",
        "        # Try different thresholds for the current class\n",
        "        for threshold in threshold_ranges[class_id]:\n",
        "            current_thresholds[class_id] = threshold\n",
        "\n",
        "            # Evaluate with current thresholds\n",
        "            class_metrics = evaluate_class_threshold(\n",
        "                model, val_loader, device, class_id, current_thresholds\n",
        "            )\n",
        "\n",
        "            # Print results - ensure all keys exist\n",
        "            precision = class_metrics.get('precision', 0.0)\n",
        "            recall = class_metrics.get('recall', 0.0)\n",
        "            f1 = class_metrics.get('f1', 0.0)\n",
        "            ap = class_metrics.get('AP', 0.0)\n",
        "\n",
        "            print(f\"{threshold:<10.2f} {precision:<10.4f} \"\n",
        "                  f\"{recall:<10.4f} {f1:<10.4f} \"\n",
        "                  f\"{ap:<10.4f}\")\n",
        "\n",
        "            # Update best threshold if F1 score is higher\n",
        "            if f1 > best_metrics[class_id]['f1']:\n",
        "                best_metrics[class_id] = class_metrics.copy()\n",
        "                best_thresholds[class_id] = threshold\n",
        "\n",
        "        print(f\"\\nBest threshold for {class_names[class_id]}: {best_thresholds[class_id]:.2f}\")\n",
        "        best_f1 = best_metrics[class_id].get('f1', 0.0)\n",
        "        best_precision = best_metrics[class_id].get('precision', 0.0)\n",
        "        best_recall = best_metrics[class_id].get('recall', 0.0)\n",
        "        best_ap = best_metrics[class_id].get('AP', 0.0)\n",
        "\n",
        "        print(f\"Best F1: {best_f1:.4f}, \"\n",
        "              f\"Precision: {best_precision:.4f}, \"\n",
        "              f\"Recall: {best_recall:.4f}, \"\n",
        "              f\"AP: {best_ap:.4f}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"OPTIMAL CONFIDENCE THRESHOLDS\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    print(f\"{'Class':<15} {'Threshold':<10}\")\n",
        "    print(\"-\" * 25)\n",
        "\n",
        "    for class_id in range(1, 5):\n",
        "        print(f\"{class_names[class_id]:<15} {best_thresholds[class_id]:<10.2f}\")\n",
        "\n",
        "    return best_thresholds\n",
        "\n",
        "def evaluate_class_threshold(model, data_loader, device, target_class, thresholds):\n",
        "    \"\"\"\n",
        "    Evaluate threshold for a specific class\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained model\n",
        "    - data_loader: Validation data loader\n",
        "    - device: Device to run on\n",
        "    - target_class: Class ID to evaluate\n",
        "    - thresholds: Dictionary of thresholds for each class\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary with precision, recall, F1, and AP for the target class\n",
        "    \"\"\"\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = [img.to(device) for img in images]\n",
        "\n",
        "            # Forward pass\n",
        "            results = model(images)\n",
        "\n",
        "            # Process each image result\n",
        "            for i, result in enumerate(results):\n",
        "                pred_boxes = result['boxes'].cpu()\n",
        "                pred_labels = result['labels'].cpu()\n",
        "                pred_scores = result['scores'].cpu()\n",
        "\n",
        "                # Get predictions for target class only\n",
        "                target_mask = pred_labels == target_class\n",
        "                target_boxes = pred_boxes[target_mask]\n",
        "                target_scores = pred_scores[target_mask]\n",
        "\n",
        "                # Apply threshold\n",
        "                threshold_mask = target_scores >= thresholds[target_class]\n",
        "                target_boxes = target_boxes[threshold_mask]\n",
        "\n",
        "                # Get ground truth for target class\n",
        "                gt_boxes = targets[i]['boxes'].cpu()\n",
        "                gt_labels = targets[i]['labels'].cpu()\n",
        "                gt_mask = gt_labels == target_class\n",
        "                gt_boxes = gt_boxes[gt_mask]\n",
        "\n",
        "                # Match predictions to ground truth\n",
        "                matches = match_boxes(target_boxes, gt_boxes)\n",
        "\n",
        "                # Create binary arrays for this image\n",
        "                if len(gt_boxes) == 0:\n",
        "                    # No ground truth objects - all predictions are false positives\n",
        "                    all_predictions.extend([0] * len(matches))\n",
        "                else:\n",
        "                    # Add true/false positives\n",
        "                    all_predictions.extend([1 if m else 0 for m in matches])\n",
        "\n",
        "                    # Add false negatives for unmatched ground truths\n",
        "                    missed_gt = len(gt_boxes) - sum(matches)\n",
        "                    if missed_gt > 0:\n",
        "                        all_targets.extend([1] * len(gt_boxes))\n",
        "                        all_predictions.extend([0] * missed_gt)\n",
        "                    else:\n",
        "                        all_targets.extend([1] * len(gt_boxes))\n",
        "\n",
        "    # Calculate metrics\n",
        "    if not all_predictions or not all_targets:\n",
        "        return {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'AP': 0.0}\n",
        "\n",
        "    # Make sure arrays have the same length\n",
        "    if len(all_predictions) != len(all_targets):\n",
        "        # Truncate the longer array to match the shorter one\n",
        "        min_len = min(len(all_predictions), len(all_targets))\n",
        "        all_predictions = all_predictions[:min_len]\n",
        "        all_targets = all_targets[:min_len]\n",
        "\n",
        "    # Convert to numpy arrays for calculation\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_targets = np.array(all_targets)\n",
        "\n",
        "    try:\n",
        "        # Calculate precision, recall, F1\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            all_targets, all_predictions, average='binary', zero_division=0\n",
        "        )\n",
        "\n",
        "        # Approximate AP (simplified)\n",
        "        AP = precision * recall\n",
        "\n",
        "        return {\n",
        "            'precision': float(precision),\n",
        "            'recall': float(recall),\n",
        "            'f1': float(f1),\n",
        "            'AP': float(AP)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating metrics: {e}\")\n",
        "        print(f\"Predictions array length: {len(all_predictions)}\")\n",
        "        print(f\"Targets array length: {len(all_targets)}\")\n",
        "        # Return default metrics on error\n",
        "        return {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'AP': 0.0}\n",
        "\n",
        "\n",
        "\n",
        "# First define the helper functions\n",
        "def tensor_to_image(tensor):\n",
        "    # Convert tensor to numpy and transpose dimensions\n",
        "    img = tensor.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # Denormalize\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img = std * img + mean\n",
        "    img = np.clip(img, 0, 1)\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    return img\n",
        "\n",
        "def draw_boxes(image, target):\n",
        "    import cv2\n",
        "    image = image.copy()\n",
        "\n",
        "    # Define colors for each class\n",
        "    class_colors = {\n",
        "        1: (0, 255, 0),    # Green for encampments\n",
        "        2: (0, 0, 255)     # Blue for carts\n",
        "    }\n",
        "\n",
        "    # Define class names\n",
        "    class_names = {\n",
        "        1: 'Encampments',\n",
        "        2: 'Cart'\n",
        "    }\n",
        "\n",
        "    # Get boxes and labels\n",
        "    boxes = target['boxes'].cpu().numpy().astype(np.int32)\n",
        "    labels = target['labels'].cpu().numpy()\n",
        "\n",
        "    # Draw boxes\n",
        "    for box, label in zip(boxes, labels):\n",
        "        color = class_colors.get(label.item(), (255, 255, 255))\n",
        "        cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]),\n",
        "                     color, 2, cv2.LINE_AA)\n",
        "        cv2.putText(image, f\"{class_names.get(label.item(), 'Unknown')}\",\n",
        "                   (box[0], box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "def match_boxes(pred_boxes, gt_boxes, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Match predicted boxes to ground truth boxes\n",
        "\n",
        "    Parameters:\n",
        "    - pred_boxes: Predicted bounding boxes\n",
        "    - gt_boxes: Ground truth bounding boxes\n",
        "    - iou_threshold: IoU threshold for considering a match\n",
        "\n",
        "    Returns:\n",
        "    - List of boolean values indicating whether each prediction matched a ground truth\n",
        "    \"\"\"\n",
        "    if len(pred_boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    if len(gt_boxes) == 0:\n",
        "        return [False] * len(pred_boxes)\n",
        "\n",
        "    matches = []\n",
        "    matched_gt = set()\n",
        "\n",
        "    # For each prediction, find the best matching ground truth\n",
        "    for pred_box in pred_boxes:\n",
        "        best_iou = 0\n",
        "        best_gt_idx = -1\n",
        "\n",
        "        for gt_idx, gt_box in enumerate(gt_boxes):\n",
        "            if gt_idx in matched_gt:\n",
        "                continue  # This ground truth is already matched\n",
        "\n",
        "            iou = calculate_iou(pred_box, gt_box)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_gt_idx = gt_idx\n",
        "\n",
        "        # Check if we found a match\n",
        "        if best_iou >= iou_threshold and best_gt_idx not in matched_gt:\n",
        "            matches.append(True)\n",
        "            matched_gt.add(best_gt_idx)\n",
        "        else:\n",
        "            matches.append(False)\n",
        "\n",
        "    return matches\n",
        "\n",
        "def run_experiment(data_dir, train_xml_files, val_xml_files,\n",
        "                  augmentation_type=\"basic\", sampling_strategy=\"class_aware\",\n",
        "                  loss_reweighting=False, num_epochs=15, experiment_name=\"experiment\",\n",
        "                  confidence_thresholds=None):\n",
        "    \"\"\"\n",
        "    Run training experiment with specified configuration\n",
        "\n",
        "    Parameters:\n",
        "    - data_dir: Directory containing images and XML files\n",
        "    - train_xml_files: List of XML files for training\n",
        "    - val_xml_files: List of XML files for validation\n",
        "    - augmentation_type: \"basic\" or \"mosaic_mixup\"\n",
        "    - sampling_strategy: \"class_aware\" or \"random\"\n",
        "    - loss_reweighting: Whether to apply loss reweighting\n",
        "    - num_epochs: Number of training epochs\n",
        "    - experiment_name: Name for saving models and visualizations\n",
        "    - confidence_thresholds: Optional dictionary of class-specific confidence thresholds\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary with training results\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EXPERIMENT: {experiment_name}\")\n",
        "    print(f\"Augmentation: {augmentation_type}\")\n",
        "    print(f\"Sampling Strategy: {sampling_strategy}\")\n",
        "    print(f\"Loss Reweighting: {loss_reweighting}\")\n",
        "\n",
        "    # Default confidence thresholds if none provided\n",
        "    if confidence_thresholds is None:\n",
        "        confidence_thresholds = {1: 0.55, 2: 0.8, 3: 0.45, 4: 0.65}\n",
        "\n",
        "    print(f\"Confidence Thresholds: {confidence_thresholds}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Create datasets with specified augmentation\n",
        "    train_dataset = HomelessDataset(data_dir, train_xml_files,\n",
        "                                   transform=get_basic_transform(train=True),\n",
        "                                   augmentation_type=augmentation_type)\n",
        "    val_dataset = HomelessDataset(data_dir, val_xml_files,\n",
        "                                 transform=get_basic_transform(train=False),\n",
        "                                 augmentation_type=\"basic\")  # Always use basic for validation\n",
        "\n",
        "    print(f\"Training samples: {len(train_dataset)}\")\n",
        "    print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "    # Calculate class weights (for either sampling or loss reweighting)\n",
        "    class_counts = {1: 0, 2: 0, 3: 0, 4: 0}\n",
        "\n",
        "    print(\"Calculating class distribution...\")\n",
        "    for idx in tqdm(range(len(train_dataset))):\n",
        "        _, target, is_valid = train_dataset[idx]\n",
        "        if not is_valid:\n",
        "            continue\n",
        "\n",
        "        if 'labels' in target:\n",
        "            for label in target['labels']:\n",
        "                class_id = label.item()\n",
        "                if class_id in class_counts:\n",
        "                    class_counts[class_id] += 1\n",
        "\n",
        "    # Calculate weights from class distribution\n",
        "    total_instances = sum(class_counts.values())\n",
        "    class_weights = {}\n",
        "\n",
        "    print(\"\\nClass distribution and weights:\")\n",
        "    print(f\"{'Class':<10} {'Count':<10} {'Weight':<10}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    for class_id, count in class_counts.items():\n",
        "        if count > 0:\n",
        "            # Calculate inverse frequency weight\n",
        "            weight = total_instances / (count * len(class_counts))\n",
        "            class_weights[class_id] = weight\n",
        "            print(f\"{class_id:<10} {count:<10} {weight:<10.4f}\")\n",
        "        else:\n",
        "            class_weights[class_id] = 1.0\n",
        "\n",
        "    # Create data loader based on sampling strategy\n",
        "    if sampling_strategy == \"class_aware\":\n",
        "        # Get weights for sampler\n",
        "        sample_weights = train_dataset.get_sample_weights()\n",
        "\n",
        "        # Create weighted sampler\n",
        "        weighted_sampler = WeightedRandomSampler(\n",
        "            weights=sample_weights,\n",
        "            num_samples=len(sample_weights),\n",
        "            replacement=True\n",
        "        )\n",
        "\n",
        "        # Create data loader with weighted sampler\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=4,\n",
        "            sampler=weighted_sampler,\n",
        "            collate_fn=collate_fn,\n",
        "            num_workers=2\n",
        "        )\n",
        "        print(\"Using class-aware sampling\")\n",
        "    else:  # random sampling\n",
        "        # Create data loader with random sampling\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=4,\n",
        "            shuffle=True,\n",
        "            collate_fn=collate_fn,\n",
        "            num_workers=2\n",
        "        )\n",
        "        print(\"Using random sampling\")\n",
        "\n",
        "    # Validation loader is always the same\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    num_classes = 5  # Background + 4 classes\n",
        "    model = get_model(num_classes)\n",
        "    model.to(device)\n",
        "\n",
        "    # Use SGD optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(\n",
        "        params,\n",
        "        lr=0.005,\n",
        "        momentum=0.9,\n",
        "        weight_decay=0.0005\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler - cosine annealing\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max=num_epochs,\n",
        "        eta_min=1e-6\n",
        "    )\n",
        "\n",
        "    # Training parameters\n",
        "    best_metrics = None\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"val_mAP\": [],\n",
        "        \"val_IoU\": [],\n",
        "        \"class_metrics\": {\n",
        "            1: {\"f1\": [], \"AP\": [], \"IoU\": []},\n",
        "            2: {\"f1\": [], \"AP\": [], \"IoU\": []},\n",
        "            3: {\"f1\": [], \"AP\": [], \"IoU\": []},\n",
        "            4: {\"f1\": [], \"AP\": [], \"IoU\": []}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Training loop\n",
        "    print(\"\\nStarting training...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        # Train with appropriate loss function\n",
        "        if loss_reweighting:\n",
        "            train_loss = train_one_epoch_reweighed(\n",
        "                model, optimizer, train_loader, device, epoch, class_weights, print_freq=10\n",
        "            )\n",
        "            print(f\"Using loss reweighting with weights: {class_weights}\")\n",
        "        else:\n",
        "            train_loss = train_one_epoch(\n",
        "                model, optimizer, train_loader, device, epoch, print_freq=10\n",
        "            )\n",
        "            print(\"Not using loss reweighting\")\n",
        "\n",
        "        # Step LR scheduler\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # Evaluate with comprehensive metrics\n",
        "        val_metrics = evaluate_model(model, val_loader, device)\n",
        "\n",
        "        # Log history\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_mAP\"].append(val_metrics[\"mAP\"])\n",
        "        history[\"val_IoU\"].append(val_metrics[\"IoU\"])\n",
        "\n",
        "        for cls in range(1, 5):\n",
        "            history[\"class_metrics\"][cls][\"f1\"].append(val_metrics[\"class_metrics\"][cls][\"f1\"])\n",
        "            history[\"class_metrics\"][cls][\"AP\"].append(val_metrics[\"class_metrics\"][cls][\"AP\"])\n",
        "            history[\"class_metrics\"][cls][\"IoU\"].append(val_metrics[\"class_metrics\"][cls][\"IoU\"])\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"\\nEpoch {epoch} completed:\")\n",
        "        print(f\"  Training Loss: {train_loss:.4f}\")\n",
        "        print(f\"  Validation mAP@0.5: {val_metrics['mAP']:.4f}, IoU: {val_metrics['IoU']:.4f}\")\n",
        "        print(f\"  Class AP: People: {val_metrics['class_metrics'][1]['AP']:.4f}, \"\n",
        "              f\"Encampments: {val_metrics['class_metrics'][2]['AP']:.4f}, \"\n",
        "              f\"Cart: {val_metrics['class_metrics'][3]['AP']:.4f}, \"\n",
        "              f\"Bike: {val_metrics['class_metrics'][4]['AP']:.4f}\")\n",
        "        print(f\"  Class F1: People: {val_metrics['class_metrics'][1]['f1']:.4f}, \"\n",
        "              f\"Encampments: {val_metrics['class_metrics'][2]['f1']:.4f}, \"\n",
        "              f\"Cart: {val_metrics['class_metrics'][3]['f1']:.4f}, \"\n",
        "              f\"Bike: {val_metrics['class_metrics'][4]['f1']:.4f}\")\n",
        "        print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # Save best model based on mAP\n",
        "        if best_metrics is None or val_metrics[\"mAP\"] > best_metrics[\"mAP\"]:\n",
        "            best_metrics = val_metrics\n",
        "            model_path = f\"maskrcnn_{experiment_name}_weights.pth\"\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(f\"  New best mAP: {val_metrics['mAP']:.4f}, model saved to {model_path}\")\n",
        "\n",
        "    print(f\"\\nTraining complete! Best mAP: {best_metrics['mAP']:.4f}\")\n",
        "\n",
        "    # Load best model for visualization\n",
        "    model.load_state_dict(torch.load(f\"maskrcnn_{experiment_name}_weights.pth\"))\n",
        "\n",
        "    # Visualize predictions with provided thresholds\n",
        "    print(\"Generating prediction visualizations...\")\n",
        "    viz_path = visualize_predictions(\n",
        "        model, val_dataset, device, num_images=5,\n",
        "        confidence_thresholds=confidence_thresholds,\n",
        "        save_path=f\"predictions_{experiment_name}.png\"\n",
        "    )\n",
        "    print(f\"Visualization saved to {viz_path}\")\n",
        "\n",
        "    # Return results\n",
        "    results = {\n",
        "        \"experiment_name\": experiment_name,\n",
        "        \"augmentation_type\": augmentation_type,\n",
        "        \"sampling_strategy\": sampling_strategy,\n",
        "        \"loss_reweighting\": loss_reweighting,\n",
        "        \"confidence_thresholds\": confidence_thresholds,\n",
        "        \"best_metrics\": best_metrics,\n",
        "        \"history\": history,\n",
        "        \"model_path\": f\"maskrcnn_{experiment_name}_weights.pth\",\n",
        "        \"viz_path\": viz_path\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "def create_train_val_test_split(xml_files, val_size=0.15, test_size=0.15, random_state=42):\n",
        "    \"\"\"\n",
        "    Create a 3-way split of the data into training, validation, and test sets.\n",
        "\n",
        "    Parameters:\n",
        "    - xml_files: List of XML filenames\n",
        "    - val_size: Proportion of data to use for validation\n",
        "    - test_size: Proportion of data to use for testing\n",
        "    - random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    - train_xml_files, val_xml_files, test_xml_files: Lists of XML filenames\n",
        "    \"\"\"\n",
        "    # First split off the test set\n",
        "    train_val_files, test_xml_files = train_test_split(\n",
        "        xml_files,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Then split the remaining data into train and validation\n",
        "    # Adjust validation size to be relative to the train_val_files size\n",
        "    effective_val_size = val_size / (1 - test_size)\n",
        "\n",
        "    train_xml_files, val_xml_files = train_test_split(\n",
        "        train_val_files,\n",
        "        test_size=effective_val_size,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    return train_xml_files, val_xml_files, test_xml_files\n",
        "\n",
        "# Function to evaluate on test set\n",
        "def evaluate_on_test_set(model, test_loader, device, confidence_thresholds=None):\n",
        "    \"\"\"\n",
        "    Evaluate model performance on the test set\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained model\n",
        "    - test_loader: DataLoader for test set\n",
        "    - device: Device to run evaluation on\n",
        "    - confidence_thresholds: Dictionary mapping class IDs to confidence thresholds\n",
        "\n",
        "    Returns:\n",
        "    - test_metrics: Dictionary containing evaluation metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize metrics accumulators for all classes\n",
        "    metrics_accumulator = {\n",
        "        \"mAP\": [],\n",
        "        \"IoU\": [],\n",
        "        \"class_metrics\": {\n",
        "            1: {\"precision\": [], \"recall\": [], \"f1\": [], \"AP\": [], \"IoU\": []},\n",
        "            2: {\"precision\": [], \"recall\": [], \"f1\": [], \"AP\": [], \"IoU\": []},\n",
        "            3: {\"precision\": [], \"recall\": [], \"f1\": [], \"AP\": [], \"IoU\": []},\n",
        "            4: {\"precision\": [], \"recall\": [], \"f1\": [], \"AP\": [], \"IoU\": []}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in test_loader:\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            # Get predictions\n",
        "            predictions = model(images)\n",
        "\n",
        "            # Apply confidence thresholds if provided\n",
        "            if confidence_thresholds:\n",
        "                filtered_predictions = []\n",
        "                for prediction in predictions:\n",
        "                    keep_indices = []\n",
        "                    for j, label in enumerate(prediction['labels']):\n",
        "                        label_id = label.item()\n",
        "                        if label_id in confidence_thresholds and prediction['scores'][j] >= confidence_thresholds[label_id]:\n",
        "                            keep_indices.append(j)\n",
        "\n",
        "                    if keep_indices:\n",
        "                        # Create new filtered prediction with all required keys\n",
        "                        filtered_pred = {\n",
        "                            'boxes': prediction['boxes'][keep_indices],\n",
        "                            'labels': prediction['labels'][keep_indices],\n",
        "                            'scores': prediction['scores'][keep_indices]\n",
        "                        }\n",
        "                    else:\n",
        "                        # Create empty prediction\n",
        "                        filtered_pred = {\n",
        "                            'boxes': torch.zeros((0, 4), device=device),\n",
        "                            'labels': torch.zeros(0, dtype=torch.int64, device=device),\n",
        "                            'scores': torch.zeros(0, device=device)\n",
        "                        }\n",
        "\n",
        "                    filtered_predictions.append(filtered_pred)\n",
        "\n",
        "                # Replace original predictions with filtered ones\n",
        "                predictions = filtered_predictions\n",
        "\n",
        "            # Calculate metrics for each image\n",
        "            for i, (prediction, target) in enumerate(zip(predictions, targets)):\n",
        "                pred_boxes = prediction['boxes'].cpu()\n",
        "                pred_labels = prediction['labels'].cpu()\n",
        "                pred_scores = prediction['scores'].cpu()\n",
        "\n",
        "                gt_boxes = target['boxes'].cpu()\n",
        "                gt_labels = target['labels'].cpu()\n",
        "\n",
        "                # Calculate metrics\n",
        "                metrics = calculate_metrics(\n",
        "                    pred_boxes, pred_labels, pred_scores,\n",
        "                    gt_boxes, gt_labels, iou_threshold=0.5\n",
        "                )\n",
        "\n",
        "                # Accumulate metrics\n",
        "                metrics_accumulator[\"mAP\"].append(metrics[\"mAP\"])\n",
        "                metrics_accumulator[\"IoU\"].append(metrics[\"IoU\"])\n",
        "\n",
        "                # Accumulate for all classes\n",
        "                for cls in range(1, 5):\n",
        "                    if cls in metrics[\"class_metrics\"]:\n",
        "                        for metric_name, value in metrics[\"class_metrics\"][cls].items():\n",
        "                            metrics_accumulator[\"class_metrics\"][cls][metric_name].append(value)\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_metrics = {\n",
        "        \"mAP\": np.mean(metrics_accumulator[\"mAP\"]) if metrics_accumulator[\"mAP\"] else 0.0,\n",
        "        \"IoU\": np.mean(metrics_accumulator[\"IoU\"]) if metrics_accumulator[\"IoU\"] else 0.0,\n",
        "        \"class_metrics\": {}\n",
        "    }\n",
        "\n",
        "    # Calculate class averages\n",
        "    for cls in range(1, 5):\n",
        "        avg_metrics[\"class_metrics\"][cls] = {}\n",
        "        for metric_name in [\"precision\", \"recall\", \"f1\", \"AP\", \"IoU\"]:\n",
        "            values = metrics_accumulator[\"class_metrics\"][cls][metric_name]\n",
        "            avg_metrics[\"class_metrics\"][cls][metric_name] = np.mean(values) if values else 0.0\n",
        "\n",
        "    return avg_metrics\n",
        "\n",
        "# Function to log test results\n",
        "def log_test_results(experiment_name, test_metrics, confidence_thresholds=None):\n",
        "    \"\"\"\n",
        "    Log the test results for an experiment to a file\n",
        "\n",
        "    Parameters:\n",
        "    - experiment_name: Name of the experiment\n",
        "    - test_metrics: Dictionary containing evaluation metrics on test set\n",
        "    - confidence_thresholds: Dictionary mapping class IDs to confidence thresholds\n",
        "    \"\"\"\n",
        "    log_file = f\"test_results_{experiment_name}.txt\"\n",
        "\n",
        "    with open(log_file, 'w') as f:\n",
        "        f.write(f\"TEST RESULTS FOR EXPERIMENT: {experiment_name}\\n\")\n",
        "        f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "        if confidence_thresholds:\n",
        "            f.write(f\"Confidence Thresholds: {confidence_thresholds}\\n\\n\")\n",
        "\n",
        "        f.write(f\"Overall Metrics:\\n\")\n",
        "        f.write(f\"  mAP@0.5: {test_metrics['mAP']:.4f}\\n\")\n",
        "        f.write(f\"  IoU: {test_metrics['IoU']:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(f\"Class-Specific Metrics:\\n\")\n",
        "\n",
        "        class_names = {1: 'People', 2: 'Encampments', 3: 'Cart', 4: 'Bike'}\n",
        "\n",
        "        for cls in range(1, 5):\n",
        "            f.write(f\"  Class {cls} ({class_names[cls]}):\\n\")\n",
        "            f.write(f\"    Precision: {test_metrics['class_metrics'][cls]['precision']:.4f}\\n\")\n",
        "            f.write(f\"    Recall: {test_metrics['class_metrics'][cls]['recall']:.4f}\\n\")\n",
        "            f.write(f\"    F1: {test_metrics['class_metrics'][cls]['f1']:.4f}\\n\")\n",
        "            f.write(f\"    AP: {test_metrics['class_metrics'][cls]['AP']:.4f}\\n\")\n",
        "            f.write(f\"    IoU: {test_metrics['class_metrics'][cls]['IoU']:.4f}\\n\\n\")\n",
        "\n",
        "    print(f\"Test results saved to {log_file}\")\n",
        "    return log_file\n",
        "def visualize_augmentations_with_boxes(data_dir, xml_files, transform=None):\n",
        "    \"\"\"\n",
        "    Visualize data augmentation techniques with bounding boxes for all types\n",
        "\n",
        "    Parameters:\n",
        "    - data_dir: Directory containing images and XML files\n",
        "    - xml_files: List of XML files\n",
        "    - transform: Optional transform to apply\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    # Create a dataset just for visualization\n",
        "    viz_dataset = HomelessDataset(\n",
        "        data_dir,\n",
        "        xml_files[:50],  # Use a subset\n",
        "        transform=None,  # Important: don't normalize during visualization\n",
        "        augmentation_type=\"basic\"\n",
        "    )\n",
        "\n",
        "    # Pick a random index with objects\n",
        "    idx = None\n",
        "    for _ in range(10):  # Try up to 10 random indices\n",
        "        try_idx = np.random.randint(0, len(viz_dataset))\n",
        "        # Check the return values from _get_image_and_targets\n",
        "        try:\n",
        "            # Instead of unpacking, just get the return value\n",
        "            result = viz_dataset._get_image_and_targets(try_idx)\n",
        "\n",
        "            # Check how many values are returned and adjust accordingly\n",
        "            if len(result) == 5:  # For Mask R-CNN version\n",
        "                raw_image, boxes, class_ids, masks, img_shape = result\n",
        "            elif len(result) == 4:  # For Faster R-CNN version\n",
        "                raw_image, boxes, class_ids, img_shape = result\n",
        "            else:\n",
        "                print(f\"Unexpected number of return values: {len(result)}\")\n",
        "                continue\n",
        "\n",
        "            if len(boxes) > 0:\n",
        "                idx = try_idx\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f\"Error with index {try_idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if idx is None:\n",
        "        print(\"Could not find any images with valid boxes. Using first image.\")\n",
        "        idx = 0\n",
        "        # Try again with first image\n",
        "        result = viz_dataset._get_image_and_targets(idx)\n",
        "\n",
        "        # Handle return values based on number of returned items\n",
        "        if len(result) == 5:\n",
        "            raw_image, boxes, class_ids, masks, img_shape = result\n",
        "        elif len(result) == 4:\n",
        "            raw_image, boxes, class_ids, img_shape = result\n",
        "        else:\n",
        "            print(f\"Still got unexpected number of values: {len(result)}\")\n",
        "            # Create dummy data\n",
        "            raw_image = np.zeros((512, 512, 3), dtype=np.uint8)\n",
        "            boxes = []\n",
        "            class_ids = []\n",
        "            img_shape = (512, 512)\n",
        "\n",
        "    # Define class colors\n",
        "    class_colors = {\n",
        "        1: (0, 255, 0),     # Green for People\n",
        "        2: (0, 0, 255),     # Blue for Encampments\n",
        "        3: (255, 0, 0),     # Red for Cart\n",
        "        4: (255, 255, 0)    # Yellow for Bike\n",
        "    }\n",
        "\n",
        "    class_names = {\n",
        "        1: 'People',\n",
        "        2: 'Encampments',\n",
        "        3: 'Cart',\n",
        "        4: 'Bike'\n",
        "    }\n",
        "\n",
        "    # 1. Show basic image with boxes\n",
        "    plt.subplot(3, 1, 1)\n",
        "    image_with_boxes = raw_image.copy()\n",
        "    for box, class_id in zip(boxes, class_ids):\n",
        "        x1, y1, x2, y2 = box\n",
        "        color = class_colors.get(class_id, (255, 255, 255))\n",
        "        cv2.rectangle(image_with_boxes, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(image_with_boxes, class_names.get(class_id, \"Unknown\"),\n",
        "                   (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    plt.imshow(image_with_boxes)\n",
        "    plt.title(\"Basic (No Augmentation)\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 2. Show mosaic augmentation with boxes\n",
        "    plt.subplot(3, 1, 2)\n",
        "\n",
        "    # Create a direct mosaic\n",
        "    indices = [idx] + [random.randint(0, len(viz_dataset.xml_files) - 1) for _ in range(3)]\n",
        "    mosaic_img = np.zeros((512, 512, 3), dtype=np.uint8)\n",
        "\n",
        "    # For tracking transformed boxes\n",
        "    mosaic_boxes = []\n",
        "    mosaic_class_ids = []\n",
        "\n",
        "    # Place images in mosaic grid (2x2)\n",
        "    cx, cy = 256, 256  # Center point\n",
        "    placements = [(0, 0), (cx, 0), (0, cy), (cx, cy)]  # Top-left, top-right, bottom-left, bottom-right\n",
        "\n",
        "    for i, mosaic_idx in enumerate(indices):\n",
        "        # Get image and boxes with handling for different return value counts\n",
        "        result = viz_dataset._get_image_and_targets(mosaic_idx)\n",
        "        if len(result) == 5:\n",
        "            img, img_boxes, img_class_ids, _, img_shape = result\n",
        "        elif len(result) == 4:\n",
        "            img, img_boxes, img_class_ids, img_shape = result\n",
        "        else:\n",
        "            continue  # Skip this image if unexpected return values\n",
        "\n",
        "        h, w = img_shape\n",
        "\n",
        "        # Place in the mosaic\n",
        "        x_offset, y_offset = placements[i]\n",
        "\n",
        "        # Resize image to fit quadrant\n",
        "        quadrant_w, quadrant_h = cx, cy\n",
        "        part_img = cv2.resize(img, (quadrant_w, quadrant_h))\n",
        "        mosaic_img[y_offset:y_offset+quadrant_h, x_offset:x_offset+quadrant_w] = part_img\n",
        "\n",
        "        # Scale and offset boxes\n",
        "        scale_x = quadrant_w / w\n",
        "        scale_y = quadrant_h / h\n",
        "\n",
        "        for box_idx, box in enumerate(img_boxes):\n",
        "            if len(box) == 4:  # Ensure the box has the expected format\n",
        "                x1, y1, x2, y2 = box\n",
        "\n",
        "                # Scale coordinates\n",
        "                x1_new = int(x1 * scale_x) + x_offset\n",
        "                y1_new = int(y1 * scale_y) + y_offset\n",
        "                x2_new = int(x2 * scale_x) + x_offset\n",
        "                y2_new = int(y2 * scale_y) + y_offset\n",
        "\n",
        "                # Clip to mosaic boundaries\n",
        "                x1_new = max(0, min(512-1, x1_new))\n",
        "                y1_new = max(0, min(512-1, y1_new))\n",
        "                x2_new = max(0, min(512-1, x2_new))\n",
        "                y2_new = max(0, min(512-1, y2_new))\n",
        "\n",
        "                # Check if the box is still valid\n",
        "                if x2_new > x1_new and y2_new > y1_new and (x2_new - x1_new) >= 5 and (y2_new - y1_new) >= 5:\n",
        "                    mosaic_boxes.append([x1_new, y1_new, x2_new, y2_new])\n",
        "                    if box_idx < len(img_class_ids):\n",
        "                        mosaic_class_ids.append(img_class_ids[box_idx])\n",
        "                    else:\n",
        "                        mosaic_class_ids.append(1)  # Default to class 1 if out of bounds\n",
        "\n",
        "    # Draw boxes on mosaic\n",
        "    mosaic_with_boxes = mosaic_img.copy()\n",
        "    for box, class_id in zip(mosaic_boxes, mosaic_class_ids):\n",
        "        x1, y1, x2, y2 = box\n",
        "        color = class_colors.get(class_id, (255, 255, 255))\n",
        "        cv2.rectangle(mosaic_with_boxes, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(mosaic_with_boxes, class_names.get(class_id, \"Unknown\"),\n",
        "                   (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    plt.imshow(mosaic_with_boxes)\n",
        "    plt.title(\"Mosaic Augmentation\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 3. Show mixup augmentation with boxes\n",
        "    plt.subplot(3, 1, 3)\n",
        "\n",
        "    # Create a direct mixup without normalization for visualization\n",
        "    idx2 = random.randint(0, len(viz_dataset.xml_files) - 1)\n",
        "\n",
        "    # Get first image with handling for different return value counts\n",
        "    result1 = viz_dataset._get_image_and_targets(idx)\n",
        "    if len(result1) == 5:\n",
        "        img1, boxes1, class_ids1, _, img_shape1 = result1\n",
        "    elif len(result1) == 4:\n",
        "        img1, boxes1, class_ids1, img_shape1 = result1\n",
        "    else:\n",
        "        img1 = np.zeros((512, 512, 3), dtype=np.uint8)\n",
        "        boxes1 = []\n",
        "        class_ids1 = []\n",
        "        img_shape1 = (512, 512)\n",
        "\n",
        "    # Get second image with handling for different return value counts\n",
        "    result2 = viz_dataset._get_image_and_targets(idx2)\n",
        "    if len(result2) == 5:\n",
        "        img2, boxes2, class_ids2, _, img_shape2 = result2\n",
        "    elif len(result2) == 4:\n",
        "        img2, boxes2, class_ids2, img_shape2 = result2\n",
        "    else:\n",
        "        img2 = np.zeros((512, 512, 3), dtype=np.uint8)\n",
        "        boxes2 = []\n",
        "        class_ids2 = []\n",
        "        img_shape2 = (512, 512)\n",
        "\n",
        "    # Resize both images to the same size\n",
        "    h, w = 512, 512\n",
        "    img1_resized = cv2.resize(img1, (w, h))\n",
        "    img2_resized = cv2.resize(img2, (w, h))\n",
        "\n",
        "    # Calculate scale factors to adjust bounding boxes\n",
        "    h1, w1 = img_shape1\n",
        "    h2, w2 = img_shape2\n",
        "\n",
        "    scale_x1, scale_y1 = w/w1, h/h1\n",
        "    scale_x2, scale_y2 = w/w2, h/h2\n",
        "\n",
        "    # Scale boxes for both images\n",
        "    scaled_boxes1 = []\n",
        "    scaled_class_ids1 = []\n",
        "    for box_idx, box in enumerate(boxes1):\n",
        "        x1, y1, x2, y2 = box\n",
        "        x1s, y1s = int(x1 * scale_x1), int(y1 * scale_y1)\n",
        "        x2s, y2s = int(x2 * scale_x1), int(y2 * scale_y1)\n",
        "        # Clip to boundaries\n",
        "        x1s, y1s = max(0, x1s), max(0, y1s)\n",
        "        x2s, y2s = min(w, x2s), min(h, y2s)\n",
        "        # Check if valid\n",
        "        if x2s > x1s and y2s > y1s and (x2s - x1s) >= 5 and (y2s - y1s) >= 5:\n",
        "            scaled_boxes1.append([x1s, y1s, x2s, y2s])\n",
        "            if box_idx < len(class_ids1):\n",
        "                scaled_class_ids1.append(class_ids1[box_idx])\n",
        "\n",
        "    scaled_boxes2 = []\n",
        "    scaled_class_ids2 = []\n",
        "    for box_idx, box in enumerate(boxes2):\n",
        "        x1, y1, x2, y2 = box\n",
        "        x1s, y1s = int(x1 * scale_x2), int(y1 * scale_y2)\n",
        "        x2s, y2s = int(x2 * scale_x2), int(y2 * scale_y2)\n",
        "        # Clip to boundaries\n",
        "        x1s, y1s = max(0, x1s), max(0, y1s)\n",
        "        x2s, y2s = min(w, x2s), min(h, y2s)\n",
        "        # Check if valid\n",
        "        if x2s > x1s and y2s > y1s and (x2s - x1s) >= 5 and (y2s - y1s) >= 5:\n",
        "            scaled_boxes2.append([x1s, y1s, x2s, y2s])\n",
        "            if box_idx < len(class_ids2):\n",
        "                scaled_class_ids2.append(class_ids2[box_idx])\n",
        "\n",
        "    # Mix the images with a fixed alpha for visualization clarity\n",
        "    alpha = 0.5\n",
        "    mixed_img = cv2.addWeighted(img1_resized, alpha, img2_resized, 1.0 - alpha, 0)\n",
        "\n",
        "    # Draw boxes from both images\n",
        "    mixed_with_boxes = mixed_img.copy()\n",
        "\n",
        "    # Draw boxes from first image with solid lines\n",
        "    for box, class_id in zip(scaled_boxes1, scaled_class_ids1):\n",
        "        x1, y1, x2, y2 = box\n",
        "        color = class_colors.get(class_id, (255, 255, 255))\n",
        "        cv2.rectangle(mixed_with_boxes, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(mixed_with_boxes, f\"{class_names.get(class_id, 'Unknown')} (img1)\",\n",
        "                   (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    # Draw boxes from second image with dashed lines (to distinguish them)\n",
        "    for box, class_id in zip(scaled_boxes2, scaled_class_ids2):\n",
        "        x1, y1, x2, y2 = box\n",
        "        color = class_colors.get(class_id, (255, 255, 255))\n",
        "\n",
        "        # Create dashed line effect (crude but effective for visualization)\n",
        "        for i in range(x1, x2, 5):\n",
        "            cv2.line(mixed_with_boxes, (i, y1), (min(i+3, x2), y1), color, 2)\n",
        "            cv2.line(mixed_with_boxes, (i, y2), (min(i+3, x2), y2), color, 2)\n",
        "        for i in range(y1, y2, 5):\n",
        "            cv2.line(mixed_with_boxes, (x1, i), (x1, min(i+3, y2)), color, 2)\n",
        "            cv2.line(mixed_with_boxes, (x2, i), (x2, min(i+3, y2)), color, 2)\n",
        "\n",
        "        cv2.putText(mixed_with_boxes, f\"{class_names.get(class_id, 'Unknown')} (img2)\",\n",
        "                   (x1, y2+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    plt.imshow(mixed_with_boxes)\n",
        "    plt.title(\"Mixup Augmentation\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"augmentation_examples_with_boxes.png\")\n",
        "    plt.close()\n",
        "\n",
        "    return \"augmentation_examples_with_boxes.png\"\n",
        "\n",
        "# Function to visualize predictions on test set\n",
        "def visualize_test_predictions(model, test_dataset, device, num_images=5,\n",
        "                             confidence_thresholds=None, save_path=None):\n",
        "    \"\"\"\n",
        "    Visualize model predictions on the test set\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained model\n",
        "    - test_dataset: Test dataset\n",
        "    - device: Device to run inference on\n",
        "    - num_images: Number of images to visualize\n",
        "    - confidence_thresholds: Dictionary mapping class IDs to confidence thresholds\n",
        "    - save_path: Path to save visualization image\n",
        "\n",
        "    Returns:\n",
        "    - save_path: Path where visualization was saved\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Default confidence thresholds if none provided\n",
        "    if confidence_thresholds is None:\n",
        "        confidence_thresholds = {1: 0.5, 2: 0.5, 3: 0.5, 4: 0.5}\n",
        "\n",
        "    # Class names and colors for display\n",
        "    class_names = {\n",
        "        1: 'People',\n",
        "        2: 'Encampments',\n",
        "        3: 'Cart',\n",
        "        4: 'Bike'\n",
        "    }\n",
        "\n",
        "    class_colors = {\n",
        "        1: (255, 0, 0),    # Red for people\n",
        "        2: (0, 255, 0),    # Green for encampments\n",
        "        3: (0, 0, 255),    # Blue for carts\n",
        "        4: (255, 255, 0)   # Yellow for bikes\n",
        "    }\n",
        "\n",
        "    # Get random samples\n",
        "    indices = np.random.choice(len(test_dataset), min(num_images, len(test_dataset)), replace=False)\n",
        "\n",
        "    plt.figure(figsize=(20, 20))\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        img, target, valid = test_dataset[idx]\n",
        "        if not valid:\n",
        "            continue\n",
        "\n",
        "        # Simple inference\n",
        "        with torch.no_grad():\n",
        "            prediction = model([img.to(device)])[0]\n",
        "\n",
        "        # Apply class-specific confidence thresholds\n",
        "        keep_indices = []\n",
        "        for j, label in enumerate(prediction['labels']):\n",
        "            label_id = label.item()\n",
        "            if label_id in confidence_thresholds and prediction['scores'][j] >= confidence_thresholds[label_id]:\n",
        "                keep_indices.append(j)\n",
        "\n",
        "        # Process boxes\n",
        "        if len(keep_indices) > 0:\n",
        "            boxes = prediction['boxes'][keep_indices].cpu().numpy()\n",
        "            # Ensure boxes are within image boundaries before converting to int\n",
        "            boxes[:, 0] = np.clip(boxes[:, 0], 0, img.shape[2] - 1)\n",
        "            boxes[:, 1] = np.clip(boxes[:, 1], 0, img.shape[1] - 1)\n",
        "            boxes[:, 2] = np.clip(boxes[:, 2], 0, img.shape[2] - 1)\n",
        "            boxes[:, 3] = np.clip(boxes[:, 3], 0, img.shape[1] - 1)\n",
        "            boxes = boxes.astype(np.int32)\n",
        "            labels = prediction['labels'][keep_indices].cpu().numpy()\n",
        "            scores = prediction['scores'][keep_indices].cpu().numpy()\n",
        "        else:\n",
        "            boxes = np.array([])\n",
        "            labels = np.array([])\n",
        "            scores = np.array([])\n",
        "\n",
        "        # Convert image back to numpy for display\n",
        "        image_np = img.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "        # Denormalize\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image_np = std * image_np + mean\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Create a copy for drawing\n",
        "        image_with_boxes = image_np.copy()\n",
        "\n",
        "        # Draw ground truth boxes\n",
        "        gt_boxes = target['boxes'].cpu().numpy().astype(np.int32)\n",
        "        gt_labels = target['labels'].cpu().numpy()\n",
        "\n",
        "        # Draw ground truth first\n",
        "        for box, label in zip(gt_boxes, gt_labels):\n",
        "            color = class_colors.get(label.item(), (255, 255, 255))\n",
        "            cv2.rectangle(image_with_boxes, (box[0], box[1]), (box[2], box[3]),\n",
        "                         color, 2, cv2.LINE_AA)\n",
        "            cv2.putText(image_with_boxes, f\"GT: {class_names.get(label.item(), 'Unknown')}\",\n",
        "                       (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Draw predictions\n",
        "        for box, label, score in zip(boxes, labels, scores):\n",
        "            color = class_colors.get(label.item(), (255, 255, 255))\n",
        "            cv2.rectangle(image_with_boxes, (box[0], box[1]), (box[2], box[3]),\n",
        "                         color, 2, cv2.LINE_AA)\n",
        "            cv2.putText(image_with_boxes,\n",
        "                       f\"{class_names.get(label.item(), 'Unknown')}: {score:.2f}\",\n",
        "                       (box[0], box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Display\n",
        "        plt.subplot(num_images, 1, i + 1)\n",
        "        plt.imshow(image_with_boxes)\n",
        "        plt.title(f\"Test Sample {idx} (Inference with Class-Specific Thresholds)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path is None:\n",
        "        save_path = \"test_predictions.png\"\n",
        "\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "    return save_path\n",
        "\n",
        "# Function to plot test results\n",
        "def plot_test_comparison(test_results, save_path=\"test_comparison.png\"):\n",
        "    \"\"\"\n",
        "    Plot a comparison of model performance on the test set\n",
        "\n",
        "    Parameters:\n",
        "    - test_results: List of dictionaries containing test metrics\n",
        "    - save_path: Path to save the visualization\n",
        "\n",
        "    Returns:\n",
        "    - save_path: Path where the visualization was saved\n",
        "    \"\"\"\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Test Set Performance Comparison', fontsize=16)\n",
        "\n",
        "    # Get experiment names for labels\n",
        "    experiment_names = [result[\"experiment_name\"] for result in test_results]\n",
        "\n",
        "    # Get mAP and IoU values\n",
        "    mAP_values = [result[\"metrics\"][\"mAP\"] for result in test_results]\n",
        "    IoU_values = [result[\"metrics\"][\"IoU\"] for result in test_results]\n",
        "\n",
        "    # Plot mAP and IoU\n",
        "    axs[0, 0].bar(experiment_names, mAP_values, color='skyblue')\n",
        "    axs[0, 0].set_title('Test mAP@0.5')\n",
        "    axs[0, 0].set_ylabel('mAP')\n",
        "    axs[0, 0].set_ylim(0, 1.0)\n",
        "    plt.setp(axs[0, 0].get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "    axs[0, 1].bar(experiment_names, IoU_values, color='lightgreen')\n",
        "    axs[0, 1].set_title('Test IoU')\n",
        "    axs[0, 1].set_ylabel('IoU')\n",
        "    axs[0, 1].set_ylim(0, 1.0)\n",
        "    plt.setp(axs[0, 1].get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "    # Class-specific metrics\n",
        "    class_names = {1: 'People', 2: 'Encampments', 3: 'Cart', 4: 'Bike'}\n",
        "\n",
        "    # Get F1 and AP values by class\n",
        "    f1_by_class = {\n",
        "        cls: [result[\"metrics\"][\"class_metrics\"][cls][\"f1\"] for result in test_results]\n",
        "        for cls in range(1, 5)\n",
        "    }\n",
        "\n",
        "    ap_by_class = {\n",
        "        cls: [result[\"metrics\"][\"class_metrics\"][cls][\"AP\"] for result in test_results]\n",
        "        for cls in range(1, 5)\n",
        "    }\n",
        "\n",
        "    # Set up bar positions\n",
        "    x = np.arange(len(experiment_names))\n",
        "    width = 0.2\n",
        "\n",
        "    # Plot F1 scores by class\n",
        "    for i, cls in enumerate(range(1, 5)):\n",
        "        axs[1, 0].bar(x + (i-1.5)*width, f1_by_class[cls], width,\n",
        "                    label=class_names[cls],\n",
        "                    color=f'C{i}')\n",
        "\n",
        "    axs[1, 0].set_title('Test F1 Scores by Class')\n",
        "    axs[1, 0].set_ylabel('F1 Score')\n",
        "    axs[1, 0].set_xticks(x)\n",
        "    axs[1, 0].set_xticklabels(experiment_names)\n",
        "    axs[1, 0].set_ylim(0, 1.0)\n",
        "    axs[1, 0].legend()\n",
        "    plt.setp(axs[1, 0].get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "    # Plot AP by class\n",
        "    for i, cls in enumerate(range(1, 5)):\n",
        "        axs[1, 1].bar(x + (i-1.5)*width, ap_by_class[cls], width,\n",
        "                    label=class_names[cls],\n",
        "                    color=f'C{i}')\n",
        "\n",
        "    axs[1, 1].set_title('Test AP by Class')\n",
        "    axs[1, 1].set_ylabel('AP')\n",
        "    axs[1, 1].set_xticks(x)\n",
        "    axs[1, 1].set_xticklabels(experiment_names)\n",
        "    axs[1, 1].set_ylim(0, 1.0)\n",
        "    axs[1, 1].legend()\n",
        "    plt.setp(axs[1, 1].get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "    return save_path\n",
        "\n",
        "# Modify main() to run grid search before scenarios\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function with 3-way split for training, validation, and testing\n",
        "    \"\"\"\n",
        "    # Data directory\n",
        "    data_dir = \"/content/Annotated-Training-Images-For-Fast-RCNN_1\"\n",
        "\n",
        "    # Get XML files\n",
        "    xml_files = [f for f in os.listdir(data_dir) if f.endswith('.xml')]\n",
        "    print(f\"Found {len(xml_files)} XML files\")\n",
        "\n",
        "    # Create a 3-way split: train, validation, and test\n",
        "    train_xml_files, val_xml_files, test_xml_files = create_train_val_test_split(\n",
        "        xml_files, val_size=0.15, test_size=0.15, random_state=42\n",
        "    )\n",
        "    print(f\"Split: {len(train_xml_files)} training, {len(val_xml_files)} validation, {len(test_xml_files)} test\")\n",
        "\n",
        "    # Create test dataset and loader (same for all experiments)\n",
        "    test_dataset = HomelessDataset(\n",
        "        data_dir,\n",
        "        test_xml_files,\n",
        "        transform=get_basic_transform(train=False),\n",
        "        augmentation_type=\"basic\"\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    # Visualize augmentations to understand the data transformations\n",
        "    visualization_path = visualize_augmentations_with_boxes(\n",
        "        data_dir, train_xml_files, transform=get_basic_transform(train=True)\n",
        "    )\n",
        "    print(f\"Augmentation visualization saved to: {visualization_path}\")\n",
        "\n",
        "    # Run grid search for optimal confidence thresholds using validation set\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RUNNING GRID SEARCH FOR OPTIMAL CONFIDENCE THRESHOLDS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Only train the grid search model for a few epochs to save time\n",
        "    optimal_thresholds = grid_search_thresholds(\n",
        "        data_dir=data_dir,\n",
        "        train_xml_files=train_xml_files,\n",
        "        val_xml_files=val_xml_files,\n",
        "        num_epochs=5\n",
        "    )\n",
        "\n",
        "    # Store results for all scenarios\n",
        "    all_results = []\n",
        "    all_test_results = []\n",
        "    num_classes = 5\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    # Number of epochs for each experiment\n",
        "    num_epochs = 30\n",
        "\n",
        "\n",
        "\n",
        "    # Scenario 4: Mosaic+Mixup augmentation + Random sampling (with loss reweighting)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SCENARIO 4: MOSAIC AUGMENTATION + RANDOM SAMPLING (WITH LOSS REWEIGHTING)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    result4 = run_experiment(\n",
        "        data_dir=data_dir,\n",
        "        train_xml_files=train_xml_files,\n",
        "        val_xml_files=val_xml_files,\n",
        "        augmentation_type=\"mosaic_mixup\",\n",
        "        sampling_strategy=\"random\",\n",
        "        loss_reweighting=True,\n",
        "        num_epochs=num_epochs,\n",
        "        experiment_name=\"mosaic_random_reweighted\",\n",
        "        confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "    all_results.append(result4)\n",
        "\n",
        "    # Load best model for test evaluation\n",
        "    model4 = get_model(num_classes)\n",
        "    model4.load_state_dict(torch.load(result4['model_path']))\n",
        "    model4.to(device)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\nEvaluating Scenario 4 on test set...\")\n",
        "    test_metrics4 = evaluate_on_test_set(\n",
        "        model4, test_loader, device, confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "\n",
        "    # Log test results\n",
        "    log_file4 = log_test_results(\n",
        "        result4['experiment_name'],\n",
        "        test_metrics4,\n",
        "        confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "\n",
        "    # Visualize predictions on test set\n",
        "    test_viz_path4 = visualize_test_predictions(\n",
        "        model4,\n",
        "        test_dataset,\n",
        "        device,\n",
        "        num_images=5,\n",
        "        confidence_thresholds=optimal_thresholds,\n",
        "        save_path=f\"test_predictions_{result4['experiment_name']}.png\"\n",
        "    )\n",
        "\n",
        "    # Add test results to tracking\n",
        "    test_result4 = {\n",
        "        \"experiment_name\": result4[\"experiment_name\"],\n",
        "        \"metrics\": test_metrics4,\n",
        "        \"log_file\": log_file4,\n",
        "        \"viz_path\": test_viz_path4\n",
        "    }\n",
        "    all_test_results.append(test_result4)\n",
        "\n",
        "    # Print comparison of all scenarios on validation\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPREHENSIVE COMPARISON OF ALL SCENARIOS (VALIDATION)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Table header\n",
        "    print(f\"{'Scenario':<10} {'Augmentation':<15} {'Sampling':<15} {'Loss Reweight':<15} {'Val mAP':<10}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Print results for each scenario\n",
        "    for i, result in enumerate(all_results):\n",
        "        print(f\"{i+1:<10} \"\n",
        "              f\"{result['augmentation_type']:<15} \"\n",
        "              f\"{result['sampling_strategy']:<15} \"\n",
        "              f\"{'Yes' if result['loss_reweighting'] else 'No':<15} \"\n",
        "              f\"{result['best_metrics']['mAP']:<10.4f}\")\n",
        "\n",
        "    # Print comparison of all scenarios on test set\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPREHENSIVE COMPARISON OF ALL SCENARIOS (TEST SET)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Table header\n",
        "    print(f\"{'Scenario':<10} {'Augmentation':<15} {'Sampling':<15} {'Loss Reweight':<15} {'Test mAP':<10} {'Test IoU':<10}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Print results for each scenario\n",
        "    for i, (result, test_result) in enumerate(zip(all_results, all_test_results)):\n",
        "        print(f\"{i+1:<10} \"\n",
        "              f\"{result['augmentation_type']:<15} \"\n",
        "              f\"{result['sampling_strategy']:<15} \"\n",
        "              f\"{'Yes' if result['loss_reweighting'] else 'No':<15} \"\n",
        "              f\"{test_result['metrics']['mAP']:<10.4f} \"\n",
        "              f\"{test_result['metrics']['IoU']:<10.4f}\")\n",
        "\n",
        "    # Print class-specific AP comparison for test set\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TEST SET CLASS-SPECIFIC AVERAGE PRECISION (AP)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Table header for class AP\n",
        "    print(f\"{'Scenario':<10} {'People':<10} {'Encampments':<15} {'Cart':<10} {'Bike':<10}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Print class AP for each scenario\n",
        "    for i, test_result in enumerate(all_test_results):\n",
        "        print(f\"{i+1:<10} \"\n",
        "              f\"{test_result['metrics']['class_metrics'][1]['AP']:<10.4f} \"\n",
        "              f\"{test_result['metrics']['class_metrics'][2]['AP']:<15.4f} \"\n",
        "              f\"{test_result['metrics']['class_metrics'][3]['AP']:<10.4f} \"\n",
        "              f\"{test_result['metrics']['class_metrics'][4]['AP']:<10.4f}\")\n",
        "\n",
        "    # Print class-specific F1 comparison for test set\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TEST SET CLASS-SPECIFIC F1 SCORES\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Table header for class F1\n",
        "    print(f\"{'Scenario':<10} {'People':<10} {'Encampments':<15} {'Cart':<10} {'Bike':<10}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Print class F1 for each scenario\n",
        "    for i, test_result in enumerate(all_test_results):\n",
        "        print(f\"{i+1:<10} \"\n",
        "              f\"{test_result['metrics']['class_metrics'][1]['f1']:<10.4f} \"\n",
        "              f\"{test_result['metrics']['class_metrics'][2]['f1']:<15.4f} \"\n",
        "              f\"{test_result['metrics']['class_metrics'][3]['f1']:<10.4f} \"\n",
        "              f\"{test_result['metrics']['class_metrics'][4]['f1']:<10.4f}\")\n",
        "\n",
        "    # Create visualization comparing all scenarios (validation performance)\n",
        "    val_plot_path = plot_training_history(all_results, \"validation_comparison.png\")\n",
        "    print(f\"\\nValidation training history comparison plot for all scenarios saved to {val_plot_path}\")\n",
        "\n",
        "    # Create visualization for test performance\n",
        "    test_plot_path = plot_test_comparison(all_test_results, \"test_comparison.png\")\n",
        "    print(f\"Test performance comparison plot saved to {test_plot_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA94FW259zIO"
      },
      "outputs": [],
      "source": [
        "    # Scenario 1: Basic augmentation + Class-aware sampling (no loss reweighting)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SCENARIO 1: BASIC AUGMENTATION + CLASS-AWARE SAMPLING (NO LOSS REWEIGHTING)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    result1 = run_experiment(\n",
        "        data_dir=data_dir,\n",
        "        train_xml_files=train_xml_files,\n",
        "        val_xml_files=val_xml_files,\n",
        "        augmentation_type=\"basic\",\n",
        "        sampling_strategy=\"class_aware\",\n",
        "        loss_reweighting=False,\n",
        "        num_epochs=num_epochs,\n",
        "        experiment_name=\"basic_classaware\",\n",
        "        confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "    all_results.append(result1)\n",
        "\n",
        "    # Load best model for test evaluation\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    num_classes = 5  # Background + 4 classes\n",
        "\n",
        "    model1 = get_model(num_classes)\n",
        "    model1.load_state_dict(torch.load(result1['model_path']))\n",
        "    model1.to(device)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\nEvaluating Scenario 1 on test set...\")\n",
        "    test_metrics1 = evaluate_on_test_set(\n",
        "        model1, test_loader, device, confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "\n",
        "    # Log test results\n",
        "    log_file1 = log_test_results(\n",
        "        result1['experiment_name'],\n",
        "        test_metrics1,\n",
        "        confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "\n",
        "    # Visualize predictions on test set\n",
        "    test_viz_path1 = visualize_test_predictions(\n",
        "        model1,\n",
        "        test_dataset,\n",
        "        device,\n",
        "        num_images=5,\n",
        "        confidence_thresholds=optimal_thresholds,\n",
        "        save_path=f\"test_predictions_{result1['experiment_name']}.png\"\n",
        "    )\n",
        "\n",
        "    # Add test results to tracking\n",
        "    test_result1 = {\n",
        "        \"experiment_name\": result1[\"experiment_name\"],\n",
        "        \"metrics\": test_metrics1,\n",
        "        \"log_file\": log_file1,\n",
        "        \"viz_path\": test_viz_path1\n",
        "    }\n",
        "    all_test_results.append(test_result1)\n",
        "\n",
        "    # Scenario 2: Basic augmentation + Random sampling (with loss reweighting)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SCENARIO 2: BASIC AUGMENTATION + RANDOM SAMPLING (WITH LOSS REWEIGHTING)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    result2 = run_experiment(\n",
        "        data_dir=data_dir,\n",
        "        train_xml_files=train_xml_files,\n",
        "        val_xml_files=val_xml_files,\n",
        "        augmentation_type=\"basic\",\n",
        "        sampling_strategy=\"random\",\n",
        "        loss_reweighting=True,\n",
        "        num_epochs=num_epochs,\n",
        "        experiment_name=\"basic_random_reweighted\",\n",
        "        confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "    all_results.append(result2)\n",
        "\n",
        "    # Load best model for test evaluation\n",
        "    model2 = get_model(num_classes)\n",
        "    model2.load_state_dict(torch.load(result2['model_path']))\n",
        "    model2.to(device)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\nEvaluating Scenario 2 on test set...\")\n",
        "    test_metrics2 = evaluate_on_test_set(\n",
        "        model2, test_loader, device, confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "\n",
        "    # Log test results\n",
        "    log_file2 = log_test_results(\n",
        "        result2['experiment_name'],\n",
        "        test_metrics2,\n",
        "        confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "\n",
        "    # Visualize predictions on test set\n",
        "    test_viz_path2 = visualize_test_predictions(\n",
        "        model2,\n",
        "        test_dataset,\n",
        "        device,\n",
        "        num_images=5,\n",
        "        confidence_thresholds=optimal_thresholds,\n",
        "        save_path=f\"test_predictions_{result2['experiment_name']}.png\"\n",
        "    )\n",
        "\n",
        "    # Add test results to tracking\n",
        "    test_result2 = {\n",
        "        \"experiment_name\": result2[\"experiment_name\"],\n",
        "        \"metrics\": test_metrics2,\n",
        "        \"log_file\": log_file2,\n",
        "        \"viz_path\": test_viz_path2\n",
        "    }\n",
        "    all_test_results.append(test_result2)\n",
        "\n",
        "    # Scenario 3: Mosaic+Mixup augmentation + Class-aware sampling (no loss reweighting)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SCENARIO 3: MOSAIC AUGMENTATION + CLASS-AWARE SAMPLING (NO LOSS REWEIGHTING)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    result3 = run_experiment(\n",
        "        data_dir=data_dir,\n",
        "        train_xml_files=train_xml_files,\n",
        "        val_xml_files=val_xml_files,\n",
        "        augmentation_type=\"mosaic_mixup\",\n",
        "        sampling_strategy=\"class_aware\",\n",
        "        loss_reweighting=False,\n",
        "        num_epochs=num_epochs,\n",
        "        experiment_name=\"mosaic_classaware\",\n",
        "        confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "    all_results.append(result3)\n",
        "\n",
        "    # Load best model for test evaluation\n",
        "    model3 = get_model(num_classes)\n",
        "    model3.load_state_dict(torch.load(result3['model_path']))\n",
        "    model3.to(device)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\nEvaluating Scenario 3 on test set...\")\n",
        "    test_metrics3 = evaluate_on_test_set(\n",
        "        model3, test_loader, device, confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "\n",
        "    # Log test results\n",
        "    log_file3 = log_test_results(\n",
        "        result3['experiment_name'],\n",
        "        test_metrics3,\n",
        "        confidence_thresholds=optimal_thresholds\n",
        "    )\n",
        "\n",
        "    # Visualize predictions on test set\n",
        "    test_viz_path3 = visualize_test_predictions(\n",
        "        model3,\n",
        "        test_dataset,\n",
        "        device,\n",
        "        num_images=5,\n",
        "        confidence_thresholds=optimal_thresholds,\n",
        "        save_path=f\"test_predictions_{result3['experiment_name']}.png\"\n",
        "    )\n",
        "\n",
        "    # Add test results to tracking\n",
        "    test_result3 = {\n",
        "        \"experiment_name\": result3[\"experiment_name\"],\n",
        "        \"metrics\": test_metrics3,\n",
        "        \"log_file\": log_file3,\n",
        "        \"viz_path\": test_viz_path3\n",
        "    }\n",
        "    all_test_results.append(test_result3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dgLyZBKzMAfC",
        "outputId": "d3f7ae07-5fdb-4393-bdc2-6465886b11cd"
      },
      "outputs": [],
      "source": [
        "# If running as main script, execute the training\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
